{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단일 뉴런 (Single Neuron) - 다중 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gate Neuron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GateNeuron:\n",
    "    def __init__(self):\n",
    "        self.w = np.array([0.0, 0.0])   # weight of one input\n",
    "        self.b = np.array([0.0])   # bias\n",
    "        print(\"Initial w: {0}, b: {1}\".format(self.w, self.b))\n",
    "\n",
    "    def u(self, x):\n",
    "        return np.dot(self.w, x) + self.b\n",
    "\n",
    "    def f(self, u):\n",
    "        return max(0.0, u)\n",
    "\n",
    "    def z(self, x):\n",
    "        u = self.u(x)\n",
    "        return self.f(u)\n",
    "\n",
    "    def squared_error(self, x, z_target):\n",
    "        return 1.0 / 2.0 * math.pow(self.z(x) - z_target, 2)\n",
    "\n",
    "    def numerical_f_derivative(self, u):\n",
    "        delta = 1e-4 # 0.0001\n",
    "        return (self.f(u + delta) - self.f(u - delta)) / (2 * delta)\n",
    "\n",
    "    def d_E_over_d_w(self, input, z_target):\n",
    "        u = self.u(input)\n",
    "        z = self.f(u)\n",
    "        error = z - z_target\n",
    "        return error * self.numerical_f_derivative(u) * input\n",
    "\n",
    "    def d_E_over_d_b(self, input, z_target):\n",
    "        u = self.u(input)\n",
    "        z = self.f(u)\n",
    "        error = z - z_target\n",
    "        return error * self.numerical_f_derivative(u)\n",
    "\n",
    "    def learning(self, alpha, maxEpoch, data):\n",
    "        for i in range(maxEpoch):\n",
    "            for idx in range(data.numTrainData):\n",
    "                x = data.training_input_value[idx]\n",
    "                z_target = data.training_z_target[idx]\n",
    "                self.w = self.w - alpha * self.d_E_over_d_w(input, z_target)\n",
    "                self.b = self.b - alpha * self.d_E_over_d_b(input, z_target)\n",
    "                \n",
    "            sum = 0.0\n",
    "            for idx in range(data.numTrainData):\n",
    "                sum = sum + self.squared_error(data.training_input_value[idx], data.training_z_target[idx])\n",
    "            print(\"Epoch {0}: Error: {1}, w: {2}, b: {3}\".format(i, sum / data.numTrainData, self.w, self.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. And Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial w: [ 0.  0.], b: [ 0.]\n",
      "x: [ 0.  0.], z: 0.0, z_target: 0.0, error: 0.0\n",
      "x: [ 1.  0.], z: 0.0, z_target: 0.0, error: 0.0\n",
      "x: [ 0.  1.], z: 0.0, z_target: 0.0, error: 0.0\n",
      "x: [ 1.  1.], z: 0.0, z_target: 1.0, error: 0.5\n",
      "Epoch 0: Error: 0.08792499999999971, w: [ 0.05  0.05], b: [ 0.09]\n",
      "Epoch 1: Error: 0.07136089779860384, w: [ 0.10037869  0.10037869], b: [ 0.13030295]\n",
      "Epoch 2: Error: 0.06852770435326894, w: [ 0.11391738  0.11391738], b: [ 0.14113391]\n",
      "Epoch 3: Error: 0.06788318451022468, w: [ 0.11755575  0.11755575], b: [ 0.1440446]\n",
      "Epoch 4: Error: 0.06771841746594348, w: [ 0.11853352  0.11853352], b: [ 0.14482682]\n",
      "Epoch 5: Error: 0.06767474776897946, w: [ 0.11879629  0.11879629], b: [ 0.14503703]\n",
      "Epoch 6: Error: 0.06766305606026743, w: [ 0.1188669  0.1188669], b: [ 0.14509352]\n",
      "Epoch 7: Error: 0.06765991722664656, w: [ 0.11888588  0.11888588], b: [ 0.1451087]\n",
      "Epoch 8: Error: 0.06765907393063264, w: [ 0.11889098  0.11889098], b: [ 0.14511278]\n",
      "Epoch 9: Error: 0.06765884732105898, w: [ 0.11889235  0.11889235], b: [ 0.14511388]\n",
      "Epoch 10: Error: 0.06765878642352607, w: [ 0.11889272  0.11889272], b: [ 0.14511418]\n",
      "Epoch 11: Error: 0.06765877005809727, w: [ 0.11889282  0.11889282], b: [ 0.14511425]\n",
      "Epoch 12: Error: 0.06765876566008176, w: [ 0.11889284  0.11889284], b: [ 0.14511428]\n",
      "Epoch 13: Error: 0.06765876447816584, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 14: Error: 0.06765876416053951, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 15: Error: 0.06765876407518104, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 16: Error: 0.06765876405224194, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 17: Error: 0.06765876404607732, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 18: Error: 0.06765876404442066, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 19: Error: 0.06765876404397544, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 20: Error: 0.06765876404385582, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 21: Error: 0.06765876404382365, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 22: Error: 0.06765876404381502, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 23: Error: 0.06765876404381269, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 24: Error: 0.06765876404381205, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 25: Error: 0.0676587640438119, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 26: Error: 0.06765876404381185, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 27: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 28: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 29: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 30: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 31: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 32: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 33: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 34: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 35: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 36: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 37: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 38: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 39: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 40: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 41: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 42: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 43: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 44: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 45: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 46: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 47: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 48: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 49: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 50: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 51: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 52: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 53: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 54: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 55: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 56: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 57: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 58: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 59: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 60: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 61: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 62: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 63: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 64: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 65: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 66: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 67: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 68: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 69: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 70: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 71: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 72: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 73: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 74: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 75: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 76: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 77: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 78: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 79: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 80: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 81: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 82: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 83: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 84: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 85: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 86: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 87: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 88: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 89: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 90: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 91: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 92: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 93: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 94: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 95: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 96: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 97: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 98: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "Epoch 99: Error: 0.06765876404381183, w: [ 0.11889285  0.11889285], b: [ 0.14511428]\n",
      "x: [ 0.  0.], z: [ 0.14511428], z_target: 0.0, error: 0.010529077654371036\n",
      "x: [ 1.  0.], z: [ 0.26400714], z_target: 0.0, error: 0.034849884492072145\n",
      "x: [ 0.  1.], z: [ 0.26400714], z_target: 0.0, error: 0.034849884492072145\n",
      "x: [ 1.  1.], z: [ 0.38289999], z_target: 1.0, error: 0.19040620953673199\n"
     ]
    }
   ],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.training_input_value = np.array([(0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0)])\n",
    "        self.training_z_target = np.array([0.0, 0.0, 0.0, 1.0])\n",
    "        self.numTrainData = len(self.training_input_value)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n = GateNeuron()\n",
    "    d = Data()\n",
    "    for idx in range(d.numTrainData):\n",
    "        input = d.training_input_value[idx]\n",
    "        z = n.z(input)\n",
    "        z_target = d.training_z_target[idx]\n",
    "        error = n.squared_error(input, z_target)\n",
    "        print(\"x: {0}, z: {1}, z_target: {2}, error: {3}\".format(input, n.z(input), z_target, error))\n",
    "\n",
    "    n.learning(0.1, 100, d)\n",
    "\n",
    "    for idx in range(d.numTrainData):\n",
    "        input = d.training_input_value[idx]\n",
    "        z = n.z(input)\n",
    "        z_target = d.training_z_target[idx]\n",
    "        error = n.squared_error(input, z_target)\n",
    "        print(\"x: {0}, z: {1}, z_target: {2}, error: {3}\".format(input, n.z(input), z_target, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Or Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial w: [ 0.  0.], b: [ 0.]\n",
      "x: [ 0.  0.], z: 0.0, z_target: 0.0, error: 0.0\n",
      "x: [ 1.  0.], z: 0.0, z_target: 1.0, error: 0.5\n",
      "x: [ 0.  1.], z: 0.0, z_target: 1.0, error: 0.5\n",
      "x: [ 1.  1.], z: 0.0, z_target: 1.0, error: 0.5\n",
      "Epoch 0: Error: 0.11990145668800876, w: [ 0.18932  0.18932], b: [ 0.201456]\n",
      "Epoch 1: Error: 0.07167508547047359, w: [ 0.26165934  0.26165934], b: [ 0.25932748]\n",
      "Epoch 2: Error: 0.0620513132581235, w: [ 0.28109972  0.28109972], b: [ 0.27487977]\n",
      "Epoch 3: Error: 0.0597059989457013, w: [ 0.28632409  0.28632409], b: [ 0.27905927]\n",
      "Epoch 4: Error: 0.059093125101371886, w: [ 0.28772808  0.28772808], b: [ 0.28018247]\n",
      "Epoch 5: Error: 0.05892967908610881, w: [ 0.28810539  0.28810539], b: [ 0.28048431]\n",
      "Epoch 6: Error: 0.05888584560732623, w: [ 0.28820679  0.28820679], b: [ 0.28056543]\n",
      "Epoch 7: Error: 0.05887407241666068, w: [ 0.28823404  0.28823404], b: [ 0.28058723]\n",
      "Epoch 8: Error: 0.0588709089797813, w: [ 0.28824136  0.28824136], b: [ 0.28059309]\n",
      "Epoch 9: Error: 0.058870058876500715, w: [ 0.28824333  0.28824333], b: [ 0.28059466]\n",
      "Epoch 10: Error: 0.05886983042343856, w: [ 0.28824386  0.28824386], b: [ 0.28059509]\n",
      "Epoch 11: Error: 0.05886976902946993, w: [ 0.288244  0.288244], b: [ 0.2805952]\n",
      "Epoch 12: Error: 0.05886975253055608, w: [ 0.28824404  0.28824404], b: [ 0.28059523]\n",
      "Epoch 13: Error: 0.05886974809666264, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 14: Error: 0.05886974690510459, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 15: Error: 0.05886974658488697, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 16: Error: 0.05886974649883219, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 17: Error: 0.058869746475705906, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 18: Error: 0.05886974646949103, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 19: Error: 0.05886974646782081, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 20: Error: 0.05886974646737197, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 21: Error: 0.058869746467251356, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 22: Error: 0.05886974646721893, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 23: Error: 0.05886974646721025, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 24: Error: 0.058869746467207905, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 25: Error: 0.058869746467207267, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 26: Error: 0.05886974646720711, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 27: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 28: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 29: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 30: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 31: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 32: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 33: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 34: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 35: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 36: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 37: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 38: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 39: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 40: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 41: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 42: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 43: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 44: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 45: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 46: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 47: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 48: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 49: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 50: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 51: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 52: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 53: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 54: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 55: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 56: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 57: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 58: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 59: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 60: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 61: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 62: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 63: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 64: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 65: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 66: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 67: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 68: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 69: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 70: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 71: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 72: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 73: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 74: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 75: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 76: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 77: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 78: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 79: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 80: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 81: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 82: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 83: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 84: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 85: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 86: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 87: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 88: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 89: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 90: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 91: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 92: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 93: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 94: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 95: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 96: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 97: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 98: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "Epoch 99: Error: 0.05886974646720705, w: [ 0.28824405  0.28824405], b: [ 0.28059524]\n",
      "x: [ 0.  0.], z: [ 0.28059524], z_target: 0.0, error: 0.03936684463945226\n",
      "x: [ 1.  0.], z: [ 0.56883929], z_target: 1.0, error: 0.0929497779415466\n",
      "x: [ 0.  1.], z: [ 0.56883929], z_target: 1.0, error: 0.0929497779415466\n",
      "x: [ 1.  1.], z: [ 0.85708334], z_target: 1.0, error: 0.01021258534628274\n"
     ]
    }
   ],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.training_input_value = np.array([(0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0)])\n",
    "        self.training_z_target = np.array([0.0, 1.0, 1.0, 1.0])\n",
    "        self.numTrainData = len(self.training_input_value)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n = GateNeuron()\n",
    "    d = Data()\n",
    "    for idx in range(d.numTrainData):\n",
    "        input = d.training_input_value[idx]\n",
    "        z = n.z(input)\n",
    "        z_target = d.training_z_target[idx]\n",
    "        error = n.squared_error(input, z_target)\n",
    "        print(\"x: {0}, z: {1}, z_target: {2}, error: {3}\".format(input, n.z(input), z_target, error))\n",
    "\n",
    "    n.learning(0.1, 100, d)\n",
    "\n",
    "    for idx in range(d.numTrainData):\n",
    "        input = d.training_input_value[idx]\n",
    "        z = n.z(input)\n",
    "        z_target = d.training_z_target[idx]\n",
    "        error = n.squared_error(input, z_target)\n",
    "        print(\"x: {0}, z: {1}, z_target: {2}, error: {3}\".format(input, n.z(input), z_target, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial w: [ 0.  0.], b: [ 0.]\n",
      "x: [ 0.  0.], z: 0.0, z_target: 0.0, error: 0.0\n",
      "x: [ 1.  0.], z: 0.0, z_target: 1.0, error: 0.5\n",
      "x: [ 0.  1.], z: 0.0, z_target: 1.0, error: 0.5\n",
      "x: [ 1.  1.], z: 0.0, z_target: 0.0, error: 0.0\n",
      "Epoch 0: Error: 0.1688197766880002, w: [ 0.08932  0.08932], b: [ 0.121456]\n",
      "Epoch 1: Error: 0.15104628360517683, w: [ 0.13478549  0.13478549], b: [ 0.15782839]\n",
      "Epoch 2: Error: 0.14758783650673266, w: [ 0.14700382  0.14700382], b: [ 0.16760305]\n",
      "Epoch 3: Error: 0.1467536031738944, w: [ 0.15028735  0.15028735], b: [ 0.17022988]\n",
      "Epoch 4: Error: 0.1465362867920789, w: [ 0.15116977  0.15116977], b: [ 0.17093581]\n",
      "Epoch 5: Error: 0.1464783819641094, w: [ 0.15140691  0.15140691], b: [ 0.17112552]\n",
      "Epoch 6: Error: 0.14646285655882632, w: [ 0.15147063  0.15147063], b: [ 0.17117651]\n",
      "Epoch 7: Error: 0.1464586868732158, w: [ 0.15148776  0.15148776], b: [ 0.17119021]\n",
      "Epoch 8: Error: 0.1464575665049202, w: [ 0.15149236  0.15149236], b: [ 0.17119389]\n",
      "Epoch 9: Error: 0.1464572654322638, w: [ 0.1514936  0.1514936], b: [ 0.17119488]\n",
      "Epoch 10: Error: 0.14645718452340706, w: [ 0.15149393  0.15149393], b: [ 0.17119515]\n",
      "Epoch 11: Error: 0.14645716278014786, w: [ 0.15149402  0.15149402], b: [ 0.17119522]\n",
      "Epoch 12: Error: 0.14645715693690078, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 13: Error: 0.14645715536659537, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 14: Error: 0.14645715494459377, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 15: Error: 0.14645715483118565, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 16: Error: 0.14645715480070853, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 17: Error: 0.14645715479251814, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 18: Error: 0.1464571547903171, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 19: Error: 0.14645715478972557, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 20: Error: 0.14645715478956658, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 21: Error: 0.14645715478952387, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 22: Error: 0.1464571547895124, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 23: Error: 0.14645715478950933, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 24: Error: 0.1464571547895085, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 25: Error: 0.1464571547895083, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 26: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 27: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 28: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 29: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 30: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 31: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 32: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 33: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 34: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 35: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 36: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 37: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 38: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 39: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 40: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 41: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 42: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 43: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 44: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 45: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 46: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 47: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 48: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 49: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 50: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 51: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 52: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 53: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 54: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 55: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 56: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 57: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 58: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 59: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 60: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 61: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 62: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 63: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 64: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 65: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 66: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 67: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 68: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 69: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 70: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 71: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 72: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 73: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 74: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 75: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 76: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 77: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 78: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 79: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 80: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 81: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 82: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 83: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 84: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 85: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 86: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 87: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 88: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 89: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 90: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 91: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 92: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 93: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 94: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 95: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 96: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 97: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 98: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "Epoch 99: Error: 0.1464571547895082, w: [ 0.15149405  0.15149405], b: [ 0.17119524]\n",
      "x: [ 0.  0.], z: [ 0.17119524], z_target: 0.0, error: 0.014653905632269279\n",
      "x: [ 1.  0.], z: [ 0.3226893], z_target: 1.0, error: 0.2293748941962165\n",
      "x: [ 0.  1.], z: [ 0.3226893], z_target: 1.0, error: 0.2293748941962165\n",
      "x: [ 1.  1.], z: [ 0.47418335], z_target: 0.0, error: 0.11242492513333044\n"
     ]
    }
   ],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.training_input_value = np.array([(0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0)])\n",
    "        self.training_z_target = np.array([0.0, 1.0, 1.0, 0.0])\n",
    "        self.numTrainData = len(self.training_input_value)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n = GateNeuron()\n",
    "    d = Data()\n",
    "    for idx in range(d.numTrainData):\n",
    "        input = d.training_input_value[idx]\n",
    "        z = n.z(input)\n",
    "        z_target = d.training_z_target[idx]\n",
    "        error = n.squared_error(input, z_target)\n",
    "        print(\"x: {0}, z: {1}, z_target: {2}, error: {3}\".format(input, n.z(input), z_target, error))\n",
    "\n",
    "    n.learning(0.1, 100, d)\n",
    "\n",
    "    for idx in range(d.numTrainData):\n",
    "        input = d.training_input_value[idx]\n",
    "        z = n.z(input)\n",
    "        z_target = d.training_z_target[idx]\n",
    "        error = n.squared_error(input, z_target)\n",
    "        print(\"x: {0}, z: {1}, z_target: {2}, error: {3}\".format(input, n.z(input), z_target, error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
