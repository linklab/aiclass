{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퍼셉트론 (Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptron is an algorithm for supervised learning of **binary classifiers** \n",
    "  - The binary classifiers are functions that map an input $x$ (a vector of real numbers) to an output value $f(x)$\n",
    "    - $f(x)={\\begin{cases}1&{\\text{if }}\\mathbf {w}\\cdot \\mathbf {x}+ b>0\\\\0&{\\text{otherwise}}\\end{cases}}$\n",
    "    - where \n",
    "      - $w$ is a vector of real-valued weights (=features)\n",
    "      - $w\\cdot x$ is the dot product $\\sum _{i=1}^{m}w_{i}x_{i}$ where $m$ is the number of inputs to the perceptron and $b$ is the bias. \n",
    "        - The bias shifts the decision boundary away from the origin and does not depend on any input value.\n",
    "- It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 퍼셉트론 기본 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        self.x = tf.placeholder(tf.float32, [1, 2])\n",
    "        self.weight = tf.Variable(tf.zeros([2, 1]))  # [[0.]  [0.]] \n",
    "        self.bias = tf.Variable(tf.zeros([1]))    # [[0.]]\n",
    "    \n",
    "    def setVar(self, sess, w, b):\n",
    "        op1 = tf.assign(self.weight, w)\n",
    "        op2 = tf.assign(self.bias, b)\n",
    "        sess.run(op1)\n",
    "        sess.run(op2)\n",
    "        \n",
    "    def prediction(self, sess, x):\n",
    "        y = tf.add(tf.matmul(self.x, self.weight), self.bias)\n",
    "        classification = tf.greater_equal(y, [0.0])\n",
    "        result = sess.run(classification, feed_dict={self.x: x})\n",
    "        if result[0]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0, 0.0 - 0\n",
      "1.0, 0.0 - 0\n",
      "0.0, 1.0 - 0\n",
      "1.0, 1.0 - 1\n"
     ]
    }
   ],
   "source": [
    "# AND Gate\n",
    "# x1  x2  result\n",
    "# --------------\n",
    "#  0   0       0\n",
    "#  1   0       0\n",
    "#  0   1       0\n",
    "#  1   1       1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    data = np.array([[[0.0, 0.0]], [[1.0, 0.0]], [[0.0, 1.0]], [[1.0, 1.0]]])\n",
    "    and_gate = Perceptron()\n",
    "    w = np.array([[0.5], [0.5]])\n",
    "    b = np.array([-0.7])\n",
    "    and_gate.setVar(sess, w, b)\n",
    "    for x in data:\n",
    "        result = and_gate.prediction(sess, x)\n",
    "        print(\"{0}, {1} - {2}\".format(x[0][0], x[0][1], result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0, 0.0 - 0\n",
      "1.0, 0.0 - 1\n",
      "0.0, 1.0 - 1\n",
      "1.0, 1.0 - 1\n"
     ]
    }
   ],
   "source": [
    "# OR Gate\n",
    "# x1  x2  result\n",
    "# --------------\n",
    "#  0   0       0\n",
    "#  1   0       1\n",
    "#  0   1       1\n",
    "#  1   1       1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    data = np.array([[[0.0, 0.0]], [[1.0, 0.0]], [[0.0, 1.0]], [[1.0, 1.0]]])\n",
    "    or_gate = Perceptron()\n",
    "    w = np.array([[0.5], [0.5]])\n",
    "    b = np.array([-0.2])\n",
    "    or_gate.setVar(sess, w, b)\n",
    "    for x in data:\n",
    "        result = or_gate.prediction(sess, x)\n",
    "        print(\"{0}, {1} - {2}\".format(x[0][0], x[0][1], result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 퍼셉트론 훈련\n",
    "\n",
    "1. Initialize the weights and the bias\n",
    "  1. Weights and bias may be initialized to 0 or to a small random value.\n",
    "  \n",
    "2. For each example $j$ in our training set $D$, perform the following steps over the input ${x}_{j}$ and desired output $d_{j}$:\n",
    "  1. Calculate the predictive output:\n",
    "    1. $y_{j}(t)=f[\\mathbf {w} (t)\\cdot \\mathbf {x} _{j} + {b}(t)]$\n",
    "  2. Update the weights:\n",
    "    1. ${\\mathbf {w}(t+1)=\\mathbf {w}(t)+(d_{j}-y_{j}(t)) \\cdot \\mathbf {x}_{j}}$\n",
    "    2. ${{b}(t+1)={b}(t)+(d_{j}-y_{j}(t))}$\n",
    "\n",
    "3. The step 2 may be repeated until the iteration error ${\\frac {1}{s}}\\sum _{j=1}^{s}|d_{j}-y_{j}(t)|$ is less than a user-specified error threshold $\\gamma$, or a predetermined number of iterations have been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 다층 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiPerceptron:\n",
    "    def __init__(self):\n",
    "        self.nand_gate = Perceptron()\n",
    "        w = np.array([[-0.5], [-0.5]])\n",
    "        b = np.array([0.7])\n",
    "        self.nand_gate.setVar(sess, w, b)\n",
    "\n",
    "        self.or_gate = Perceptron()\n",
    "        w = np.array([[0.5], [0.5]])\n",
    "        b = np.array([-0.2])\n",
    "        self.or_gate.setVar(sess, w, b)\n",
    "\n",
    "        self.and_gate = Perceptron()\n",
    "        w = np.array([[0.5], [0.5]])\n",
    "        b = np.array([-0.7])\n",
    "        self.and_gate.setVar(sess, w, b)\n",
    "\n",
    "    def prediction(self, sess, x):\n",
    "        s1 = self.nand_gate.prediction(sess, x)\n",
    "        s2 = self.or_gate.prediction(sess, x)\n",
    "        y = self.and_gate.prediction(sess, [[s1, s2]])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0, 0.0 - 0\n",
      "1.0, 0.0 - 1\n",
      "0.0, 1.0 - 1\n",
      "1.0, 1.0 - 0\n"
     ]
    }
   ],
   "source": [
    "# XOR Gate\n",
    "# x1  x2  result\n",
    "# --------------\n",
    "#  0   0       0\n",
    "#  1   0       1\n",
    "#  0   1       1\n",
    "#  1   1       0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    data = [[[0.0, 0.0]], [[1.0, 0.0]], [[0.0, 1.0]], [[1.0, 1.0]]]\n",
    "    xor_gate = MultiPerceptron()\n",
    "    for x in data:\n",
    "        result = xor_gate.prediction(sess, x)\n",
    "        print(\"{0}, {1} - {2}\".format(x[0][0], x[0][1], result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
