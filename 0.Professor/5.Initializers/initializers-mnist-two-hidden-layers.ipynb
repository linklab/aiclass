{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-Neural Network-Two Hidden Layers with Variable Initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "from common.mnist import *\n",
    "from common.functions import *\n",
    "from common.layers import *\n",
    "from common.util import *\n",
    "from common.optimizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Zero_Initializer:\n",
    "    def __init__(self, input_size, hidden_layer1_size, hidden_layer2_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer1_size = hidden_layer1_size\n",
    "        self.hidden_layer2_size = hidden_layer2_size\n",
    "        self.output_size = output_size\n",
    "        self.params = {}        \n",
    "        self.params['W1'] = np.zeros((self.input_size, self.hidden_layer1_size))\n",
    "        self.params['b1'] = np.zeros(self.hidden_layer1_size)\n",
    "        self.params['W2'] = np.zeros((self.hidden_layer1_size, self.hidden_layer2_size))\n",
    "        self.params['b2'] = np.zeros(self.hidden_layer2_size)\n",
    "        self.params['W3'] = np.zeros((self.hidden_layer2_size, self.output_size))\n",
    "        self.params['b3'] = np.zeros(self.output_size)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "class N_1_Initializer:\n",
    "    def __init__(self, input_size, hidden_layer1_size, hidden_layer2_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer1_size = hidden_layer1_size\n",
    "        self.hidden_layer2_size = hidden_layer2_size\n",
    "        self.output_size = output_size\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(self.input_size, self.hidden_layer1_size)\n",
    "        self.params['b1'] = np.random.randn(self.hidden_layer1_size)\n",
    "        self.params['W2'] = np.random.randn(self.hidden_layer1_size, self.hidden_layer2_size)\n",
    "        self.params['b2'] = np.random.randn(self.hidden_layer2_size)\n",
    "        self.params['W3'] = np.random.randn(self.hidden_layer2_size, self.output_size)\n",
    "        self.params['b3'] = np.random.randn(self.output_size)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "class N_0001_Initializer:\n",
    "    def __init__(self, input_size, hidden_layer1_size, hidden_layer2_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer1_size = hidden_layer1_size\n",
    "        self.hidden_layer2_size = hidden_layer2_size\n",
    "        self.output_size = output_size\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(self.input_size, self.hidden_layer1_size) * 0.01\n",
    "        self.params['b1'] = np.random.randn(self.hidden_layer1_size) * 0.01\n",
    "        self.params['W2'] = np.random.randn(self.hidden_layer1_size, self.hidden_layer2_size) * 0.01\n",
    "        self.params['b2'] = np.random.randn(self.hidden_layer2_size) * 0.01\n",
    "        self.params['W3'] = np.random.randn(self.hidden_layer2_size, self.output_size) * 0.01\n",
    "        self.params['b3'] = np.random.randn(self.output_size) * 0.01\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "class Xavier_Initializer:\n",
    "    def __init__(self, input_size, hidden_layer1_size, hidden_layer2_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer1_size = hidden_layer1_size\n",
    "        self.hidden_layer2_size = hidden_layer2_size\n",
    "        self.output_size = output_size\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(self.input_size, self.hidden_layer1_size) / np.sqrt(self.input_size)\n",
    "        self.params['b1'] = np.random.randn(self.hidden_layer1_size) / np.sqrt(self.input_size)\n",
    "        self.params['W2'] = np.random.randn(self.hidden_layer1_size, self.hidden_layer2_size) / np.sqrt(self.hidden_layer1_size)\n",
    "        self.params['b2'] = np.random.randn(self.hidden_layer2_size) / np.sqrt(self.hidden_layer1_size)\n",
    "        self.params['W3'] = np.random.randn(self.hidden_layer2_size, self.output_size) / np.sqrt(self.hidden_layer2_size)\n",
    "        self.params['b3'] = np.random.randn(self.output_size) / np.sqrt(self.hidden_layer2_size)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "\n",
    "class He_Initializer:\n",
    "    def __init__(self, input_size, hidden_layer1_size, hidden_layer2_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer1_size = hidden_layer1_size\n",
    "        self.hidden_layer2_size = hidden_layer2_size\n",
    "        self.output_size = output_size\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(self.input_size, self.hidden_layer1_size) * np.sqrt(2) / np.sqrt(self.input_size)\n",
    "        self.params['b1'] = np.random.randn(self.hidden_layer1_size) * np.sqrt(2) / np.sqrt(self.input_size)\n",
    "        self.params['W2'] = np.random.randn(self.hidden_layer1_size, self.hidden_layer2_size) * np.sqrt(2) / np.sqrt(self.hidden_layer1_size)\n",
    "        self.params['b2'] = np.random.randn(self.hidden_layer2_size) * np.sqrt(2) / np.sqrt(self.hidden_layer1_size)\n",
    "        self.params['W3'] = np.random.randn(self.hidden_layer2_size, self.output_size) * np.sqrt(2) / np.sqrt(self.hidden_layer2_size)\n",
    "        self.params['b3'] = np.random.randn(self.output_size) * np.sqrt(2) / np.sqrt(self.hidden_layer2_size)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "from pandas import DataFrame\n",
    "\n",
    "markers = {\"Zero\": \"o\", \"N(0.0, 1.0)\": \"x\", \"N(0.0, 0.0001)\": \"s\", \"Xavier\": \"o\", \"He\": \"x\"}\n",
    "\n",
    "class TwoLayerNet2:\n",
    "    def __init__(self, initializer):\n",
    "        self.params = initializer.get_params()\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine3'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        \n",
    "        self.activations = OrderedDict()\n",
    "        self.activations[0] = None\n",
    "        \n",
    "\n",
    "        self.lastLayer = SoftmaxWithCrossEntropyLoss()\n",
    "            \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    def backpropagation_gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        din = 1\n",
    "        din = self.lastLayer.backward(din)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            din = layer.backward(din)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine3'].dW, self.layers['Affine3'].db\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    def learning(self, learning_rate, x_batch, t_batch, optimizer):\n",
    "        grads = self.backpropagation_gradient(x_batch, t_batch)\n",
    "        optimizer.update(self.params, grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../common/functions.py:55: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration completed\n",
      "1th iteration completed\n",
      "2th iteration completed\n",
      "3th iteration completed\n",
      "4th iteration completed\n",
      "5th iteration completed\n",
      "6th iteration completed\n",
      "7th iteration completed\n",
      "8th iteration completed\n",
      "9th iteration completed\n",
      "10th iteration completed\n",
      "11th iteration completed\n",
      "12th iteration completed\n",
      "13th iteration completed\n",
      "14th iteration completed\n",
      "15th iteration completed\n",
      "16th iteration completed\n",
      "17th iteration completed\n",
      "18th iteration completed\n",
      "19th iteration completed\n",
      "20th iteration completed\n",
      "21th iteration completed\n",
      "22th iteration completed\n",
      "23th iteration completed\n",
      "24th iteration completed\n",
      "25th iteration completed\n",
      "26th iteration completed\n",
      "27th iteration completed\n",
      "28th iteration completed\n",
      "29th iteration completed\n",
      "30th iteration completed\n",
      "31th iteration completed\n",
      "32th iteration completed\n",
      "33th iteration completed\n",
      "34th iteration completed\n",
      "35th iteration completed\n",
      "36th iteration completed\n",
      "37th iteration completed\n",
      "38th iteration completed\n",
      "39th iteration completed\n",
      "40th iteration completed\n"
     ]
    }
   ],
   "source": [
    "data = mnist_data(\"/Users/yhhan/git/aiclass/0.Professor/data/MNIST_data/.\")\n",
    "(img_train, label_train), (img_validation, label_validation), (img_test, label_test) = data.load_mnist(flatten=True, normalize=True, one_hot_label=True)\n",
    "\n",
    "input_size=784\n",
    "hidden_layer1_size=128\n",
    "hidden_layer2_size=128\n",
    "output_size=10\n",
    "\n",
    "initializers = {}\n",
    "initializers['Zero'] = Zero_Initializer(input_size, hidden_layer1_size, hidden_layer2_size, output_size)\n",
    "initializers['N(0.0, 1.0)'] = N_1_Initializer(input_size, hidden_layer1_size, hidden_layer2_size, output_size)\n",
    "initializers['N(0.0, 0.0001)'] = N_0001_Initializer(input_size, hidden_layer1_size, hidden_layer2_size, output_size)\n",
    "initializers['Xavier'] = Xavier_Initializer(input_size, hidden_layer1_size, hidden_layer2_size, output_size)\n",
    "initializers['He'] = He_Initializer(input_size, hidden_layer1_size, hidden_layer2_size, output_size)\n",
    "\n",
    "num_epochs = 50\n",
    "train_size = img_train.shape[0]\n",
    "batch_size = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "networks = {}\n",
    "train_errors = {}\n",
    "validation_errors = {}\n",
    "test_accuracy_values = {}\n",
    "\n",
    "optimizer = AdaGrad()\n",
    "\n",
    "for key in initializers.keys():\n",
    "    networks[key] = TwoLayerNet2(initializer=initializers[key])\n",
    "    train_errors[key] = [] \n",
    "    validation_errors[key] = []\n",
    "    test_accuracy_values[key] = []\n",
    "\n",
    "num_batch = math.ceil(train_size / batch_size)\n",
    "epoch_list = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_list.append(i)\n",
    "    for j in initializers.keys():\n",
    "        for k in range(num_batch):\n",
    "            x_batch = img_train[k * batch_size : k * batch_size + batch_size]\n",
    "            t_batch = label_train[k * batch_size : k * batch_size + batch_size]\n",
    "            networks[j].learning(learning_rate, x_batch, t_batch, optimizer)\n",
    "\n",
    "        train_loss = networks[j].loss(x_batch, t_batch)\n",
    "        train_errors[j].append(train_loss)\n",
    "\n",
    "        validation_loss = networks[j].loss(img_validation, label_validation)\n",
    "        validation_errors[j].append(validation_loss)    \n",
    "\n",
    "        test_accuracy = networks[j].accuracy(img_test, label_test)\n",
    "        test_accuracy_values[j].append(test_accuracy)\n",
    "    print(\"{0}th iteration completed\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markers = {\"Zero\": \"o\", \"N(0.0, 1.0)\": \"x\", \"N(0.0, 0.0001)\": \"s\", \"Xavier\": \"o\", \"He\": \"x\"}\n",
    "\n",
    "f, axarr = plt.subplots(2, 2, figsize=(15,10))\n",
    "for j in initializers.keys():\n",
    "    axarr[0, 0].plot(epoch_list[1:], train_errors[j][1:], marker=markers[j], markevery=2, label=j)\n",
    "axarr[0, 0].set_ylabel('Train - Total Error')\n",
    "axarr[0, 0].set_xlabel('Epochs')\n",
    "axarr[0, 0].grid(True)\n",
    "axarr[0, 0].set_title('Train Error')\n",
    "axarr[0, 0].legend(loc='upper left')\n",
    "\n",
    "for j in initializers.keys():\n",
    "    axarr[0, 1].plot(epoch_list[1:], validation_errors[j][1:], marker=markers[j], markevery=2, label=j)\n",
    "axarr[0, 1].set_ylabel('Validation - Total Error')\n",
    "axarr[0, 1].set_xlabel('Epochs')\n",
    "axarr[0, 1].grid(True)\n",
    "axarr[0, 1].set_title('Validation Error')\n",
    "axarr[0, 1].legend(loc='upper left')\n",
    "\n",
    "for j in initializers.keys():\n",
    "    axarr[1, 0].plot(epoch_list[1:], train_errors[j][1:], marker=markers[j], markevery=2, label=j)\n",
    "axarr[1, 0].set_ylabel('Train - Total Error')\n",
    "axarr[1, 0].set_xlabel('Epochs')\n",
    "axarr[1, 0].grid(True)\n",
    "axarr[1, 0].set_ylim(0, 3.0)\n",
    "axarr[1, 0].set_title('Train Error (0.00 ~ 3.00)')\n",
    "axarr[1, 0].legend(loc='upper left')\n",
    "\n",
    "for j in initializers.keys():\n",
    "    axarr[1, 1].plot(epoch_list[1:], validation_errors[j][1:], marker=markers[j], markevery=2, label=j)\n",
    "axarr[1, 1].set_ylabel('Validation - Total Error')\n",
    "axarr[1, 1].set_xlabel('Epochs')\n",
    "axarr[1, 1].grid(True)\n",
    "axarr[1, 1].set_ylim(0, 1.0)\n",
    "axarr[1, 1].set_title('Validation Error (0.00 ~ 1.00)')\n",
    "axarr[1, 1].legend(loc='upper right')\n",
    "\n",
    "f.subplots_adjust(hspace=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 1, figsize=(15,10))\n",
    "for j in initializers.keys():\n",
    "    axarr[0].plot(epoch_list[1:], test_accuracy_values[j][1:], marker=markers[j], markevery=2, label=j)\n",
    "axarr[0].set_ylabel('Test Accuracy')\n",
    "axarr[0].set_xlabel('Epochs')\n",
    "axarr[0].grid(True)\n",
    "axarr[0].set_title('Test Accuracy')\n",
    "axarr[0].legend(loc='upper left')\n",
    "\n",
    "for j in initializers.keys():\n",
    "    axarr[1].plot(epoch_list[1:], test_accuracy_values[j][1:], marker=markers[j], markevery=2, label=j)\n",
    "axarr[1].set_ylabel('Test Accuracy')\n",
    "axarr[1].set_xlabel('Epochs')\n",
    "axarr[1].grid(True)\n",
    "axarr[1].set_ylim(0.7, 1.0)\n",
    "axarr[1].set_title('Test Accuracy (0.7 ~ 1.0)')\n",
    "axarr[1].legend(loc='upper left')\n",
    "\n",
    "f.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
