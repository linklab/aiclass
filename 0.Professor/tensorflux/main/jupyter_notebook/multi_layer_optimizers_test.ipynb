{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35.0\n"
     ]
    }
   ],
   "source": [
    "# pip install numba --upgrade\n",
    "# pip install pygraphviz\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/yhhan/git/aiclass/0.Professor/\")\n",
    "\n",
    "import tensorflux.graph as tfg\n",
    "import tensorflux.deep_learning_networks as tfn\n",
    "import tensorflux.enums as tfe\n",
    "import datasource.mnist as mnist\n",
    "import tensorflux.functions as tff\n",
    "import math\n",
    "import numba\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(numba.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer Network Model - ID: 9HGIAAAI\n",
      "Multi Layer Network Model - ID: OZTW8VKB\n",
      "Multi Layer Network Model - ID: C910BE3Y\n",
      "Multi Layer Network Model - ID: U716JK5Y\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_layer1_size = 128\n",
    "hidden_layer2_size = 128\n",
    "output_size = 10\n",
    "\n",
    "x = tfg.Placeholder(name=\"x\")\n",
    "target = tfg.Placeholder(name=\"target\")\n",
    "\n",
    "n_sgd = tfn.Multi_Layer_Network(\n",
    "    input_size=input_size,\n",
    "    hidden_size_list=[hidden_layer1_size, hidden_layer2_size],\n",
    "    output_size=output_size,\n",
    "    input_node=x,\n",
    "    target_node=target,\n",
    "    initializer=tfe.Initializer.Normal.value,\n",
    "    init_sd=0.01,\n",
    "    activator=tfe.Activator.ReLU.value,\n",
    "    optimizer=tfe.Optimizer.SGD.value,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "n_momentum = tfn.Multi_Layer_Network(\n",
    "    input_size=input_size,\n",
    "    hidden_size_list=[hidden_layer1_size, hidden_layer2_size],\n",
    "    output_size=output_size,\n",
    "    input_node=x,\n",
    "    target_node=target,\n",
    "    initializer=tfe.Initializer.Normal.value,\n",
    "    init_sd=0.01,\n",
    "    activator=tfe.Activator.ReLU.value,\n",
    "    optimizer=tfe.Optimizer.Momentum.value,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# n_nag = tfn.Multi_Layer_Network(\n",
    "#     input_size=input_size,\n",
    "#     hidden_size_list=[hidden_layer1_size, hidden_layer2_size],\n",
    "#     output_size=output_size,\n",
    "#     input_node=x,\n",
    "#     target_node=target,\n",
    "#     initializer=tfe.Initializer.Normal.value,\n",
    "#     init_sd=0.01,\n",
    "#     activator=tfe.Activator.ReLU.value,\n",
    "#     optimizer=tfe.Optimizer.NAG.value,\n",
    "#     learning_rate=0.01,\n",
    "#     model_params_dir=model_params_dir\n",
    "# )\n",
    "\n",
    "n_adagrad = tfn.Multi_Layer_Network(\n",
    "    input_size=input_size,\n",
    "    hidden_size_list=[hidden_layer1_size, hidden_layer2_size],\n",
    "    output_size=output_size,\n",
    "    input_node=x,\n",
    "    target_node=target,\n",
    "    initializer=tfe.Initializer.Normal.value,\n",
    "    init_sd=0.01,\n",
    "    activator=tfe.Activator.ReLU.value,\n",
    "    optimizer=tfe.Optimizer.AdaGrad.value,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "n_adam = tfn.Multi_Layer_Network(\n",
    "    input_size=input_size,\n",
    "    hidden_size_list=[hidden_layer1_size, hidden_layer2_size],\n",
    "    output_size=output_size,\n",
    "    input_node=x,\n",
    "    target_node=target,\n",
    "    initializer=tfe.Initializer.Normal.value,\n",
    "    init_sd=0.01,\n",
    "    activator=tfe.Activator.ReLU.value,\n",
    "    optimizer=tfe.Optimizer.Adam.value,\n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = mnist.MNIST_Data(validation_size=5000, n_splits=12, is_onehot_target=True)\n",
    "#data = mnist.Fashion_MNIST_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SGD***\n",
      "-- Learning Started --\n",
      "Fold:  0\n",
      "Epoch   0 Completed - Train Error:2.30518 - Validation Error:2.30541 - Test Accuracy:0.10670 <== Minimal Val. Error\n",
      "Epoch   1 Completed - Train Error:1.91493 - Validation Error:1.92148 - Test Accuracy:0.59270 <== Minimal Val. Error\n",
      "Epoch   2 Completed - Train Error:1.12643 - Validation Error:1.14299 - Test Accuracy:0.76510 <== Minimal Val. Error\n",
      "Epoch   3 Completed - Train Error:0.77971 - Validation Error:0.72522 - Test Accuracy:0.82350 <== Minimal Val. Error\n",
      "Epoch   4 Completed - Train Error:0.59003 - Validation Error:0.56217 - Test Accuracy:0.85190 <== Minimal Val. Error\n",
      "Epoch   5 Completed - Train Error:0.50964 - Validation Error:0.47842 - Test Accuracy:0.87100 <== Minimal Val. Error\n",
      "Epoch   6 Completed - Train Error:0.46358 - Validation Error:0.42739 - Test Accuracy:0.88180 <== Minimal Val. Error\n",
      "Epoch   7 Completed - Train Error:0.43926 - Validation Error:0.39331 - Test Accuracy:0.88870 <== Minimal Val. Error\n",
      "Epoch   8 Completed - Train Error:0.38865 - Validation Error:0.36905 - Test Accuracy:0.89470 <== Minimal Val. Error\n",
      "Epoch   9 Completed - Train Error:0.39013 - Validation Error:0.35082 - Test Accuracy:0.89870 <== Minimal Val. Error\n",
      "Epoch  10 Completed - Train Error:0.33864 - Validation Error:0.33646 - Test Accuracy:0.90150 <== Minimal Val. Error\n",
      "\n",
      "[Best Epoch (based on Validation Error) and Its Performance]\n",
      "Global Epoch: 10 (Fold:  0 & Epoch: 10) - Train Error:0.33864 - Validation Error:0.33646 - Test Accuracy:0.90150\n",
      "\n",
      "Load Params from Fold   0 & Epoch  10\n",
      "Params are set to the best model!!!\n",
      "-- Learning Finished --\n",
      "\n",
      "***Momentum***\n",
      "-- Learning Started --\n",
      "Fold:  0\n",
      "Epoch   0 Completed - Train Error:2.33275 - Validation Error:2.33490 - Test Accuracy:0.07200 <== Minimal Val. Error\n",
      "Epoch   1 Completed - Train Error:0.43924 - Validation Error:0.41232 - Test Accuracy:0.87290 <== Minimal Val. Error\n",
      "Epoch   2 Completed - Train Error:0.31210 - Validation Error:0.28831 - Test Accuracy:0.91490 <== Minimal Val. Error\n",
      "Epoch   3 Completed - Train Error:0.25410 - Validation Error:0.24525 - Test Accuracy:0.92670 <== Minimal Val. Error\n",
      "Epoch   4 Completed - Train Error:0.24494 - Validation Error:0.20872 - Test Accuracy:0.93670 <== Minimal Val. Error\n",
      "Epoch   5 Completed - Train Error:0.14872 - Validation Error:0.18694 - Test Accuracy:0.94220 <== Minimal Val. Error\n",
      "Epoch   6 Completed - Train Error:0.19058 - Validation Error:0.16796 - Test Accuracy:0.94850 <== Minimal Val. Error\n",
      "Epoch   7 Completed - Train Error:0.13104 - Validation Error:0.15234 - Test Accuracy:0.95250 <== Minimal Val. Error\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9a396ef5097b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mis_numba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n",
      "\u001b[0;32m/Users/yhhan/git/aiclass/0.Professor/tensorflux/deep_learning_networks.py\u001b[0m in \u001b[0;36mlearning\u001b[0;34m(self, max_epoch, data, batch_size, print_period, is_numba, verbose)\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_process_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yhhan/git/aiclass/0.Professor/tensorflux/deep_learning_networks.py\u001b[0m in \u001b[0;36mset_learning_process_specification\u001b[0;34m(self, data, batch_size, epoch, print_period, is_numba, fold_idx, max_epoch, verbose)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmin_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mforward_final_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_numba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_final_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yhhan/git/aiclass/0.Professor/tensorflux/deep_learning_networks.py\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self, input_data, is_numba)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yhhan/git/aiclass/0.Professor/tensorflux/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, operation, feed_dict, is_numba, verbose)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# Compute the output of this operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnode_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Convert lists to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yhhan/git/aiclass/0.Professor/tensorflux/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, w_value, x_value, b_value, is_numba)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_numba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "max_epoch = 10\n",
    "\n",
    "neural_networks = {\"SGD\": n_sgd, \"Momentum\": n_momentum, \"AdaGrad\": n_adagrad, \"Adam\": n_adam}\n",
    "#neural_networks = {\"SGD\": n_sgd, \"Momentum\": n_momentum, \"Nesterov\": n_nag, \"AdaGrad\": n_adagrad, \"Adam\": n_adam}\n",
    "\n",
    "for key, neural_network in neural_networks.items():\n",
    "    print(\"***\" + key + \"***\")\n",
    "    neural_network.learning(\n",
    "        max_epoch=max_epoch, \n",
    "        data=data, \n",
    "        batch_size=batch_size, \n",
    "        print_period=1, \n",
    "        is_numba=True, \n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, neural_network in neural_networks.items():\n",
    "    print(\"{:10s} - Epoch:{:3d}, Min Train Error: {:7.5f}, Min ValidationError: {:7.5f}, Max Test Accuracy: {:7.5f}\".format(\n",
    "        key, \n",
    "        neural_networks[key].min_validation_error_epoch,\n",
    "        neural_networks[key].min_train_error,\n",
    "        neural_networks[key].min_validation_error,\n",
    "        neural_networks[key].max_test_accuracy,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#markers = {\"SGD\": \"h\", \"Momentum\": \"x\", \"Nesterov\": \"s\", \"AdaGrad\": \"o\", \"Adam\": \"1\"}\n",
    "markers = {\"SGD\": \"h\", \"Momentum\": \"x\", \"AdaGrad\": \"o\", \"Adam\": \"1\"}\n",
    "\n",
    "epoch_list = np.arange(max_epoch + 1)\n",
    "\n",
    "f, axarr = plt.subplots(2, 2, figsize=(15,10))\n",
    "\n",
    "for key, neural_network in neural_networks.items():\n",
    "    axarr[0, 0].plot(epoch_list, neural_networks[key].train_error_list, marker=markers[key], markevery=2, label=key)\n",
    "axarr[0, 0].set_ylabel('Train Error')\n",
    "axarr[0, 0].set_xlabel('Epochs')\n",
    "axarr[0, 0].grid(True)\n",
    "axarr[0, 0].set_title('Train Error')\n",
    "axarr[0, 0].legend(loc='upper left')\n",
    "\n",
    "for key, neural_network in neural_networks.items():\n",
    "    axarr[0, 1].plot(epoch_list, neural_networks[key].validation_error_list, marker=markers[key], markevery=2, label=key)\n",
    "axarr[0, 1].set_ylabel('Validation Error')\n",
    "axarr[0, 1].set_xlabel('Epochs')\n",
    "axarr[0, 1].grid(True)\n",
    "axarr[0, 1].set_title('Validation Error')\n",
    "axarr[0, 1].legend(loc='upper left')\n",
    "\n",
    "for key, neural_network in neural_networks.items():\n",
    "    axarr[1, 0].plot(epoch_list, neural_networks[key].train_error_list, marker=markers[key], markevery=2, label=key)\n",
    "axarr[1, 0].set_ylabel('Train Error')\n",
    "axarr[1, 0].set_xlabel('Epochs')\n",
    "axarr[1, 0].grid(True)\n",
    "axarr[1, 0].set_ylim(0, 0.3)\n",
    "axarr[1, 0].set_title('Train Error (0.00 ~ 0.30)')\n",
    "axarr[1, 0].legend(loc='upper left')\n",
    "\n",
    "for key, neural_network in neural_networks.items():\n",
    "    axarr[1, 1].plot(epoch_list, neural_networks[key].validation_error_list, marker=markers[key], markevery=2, label=key)\n",
    "axarr[1, 1].set_ylabel('Validation Error')\n",
    "axarr[1, 1].set_xlabel('Epochs')\n",
    "axarr[1, 1].grid(True)\n",
    "axarr[1, 1].set_ylim(0, 0.3)\n",
    "axarr[1, 1].set_title('Validation Error (0.00 ~ 0.30)')\n",
    "axarr[1, 1].legend(loc='upper left')\n",
    "\n",
    "f.subplots_adjust(hspace=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 1, figsize=(15,10))\n",
    "\n",
    "for key, neural_network in neural_networks.items():\n",
    "    axarr[0].plot(epoch_list, neural_networks[key].test_accuracy_list, marker=markers[key], markevery=1, label=key)\n",
    "axarr[0].set_ylabel('Test Accuracy')\n",
    "axarr[0].set_xlabel('Epochs')\n",
    "axarr[0].grid(True)\n",
    "axarr[0].set_title('Test Accuracy')\n",
    "axarr[0].legend(loc='upper left')\n",
    "\n",
    "for key, neural_network in neural_networks.items():\n",
    "    axarr[1].plot(epoch_list, neural_networks[key].test_accuracy_list, marker=markers[key], markevery=1, label=key)\n",
    "axarr[1].set_ylabel('Test Accuracy')\n",
    "axarr[1].set_xlabel('Epochs')\n",
    "axarr[1].grid(True)\n",
    "axarr[1].set_ylim(0.92, 0.99)\n",
    "axarr[1].set_title('Test Accuracy (0.92 ~ 0.99)')\n",
    "axarr[1].legend(loc='upper left')\n",
    "\n",
    "f.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
