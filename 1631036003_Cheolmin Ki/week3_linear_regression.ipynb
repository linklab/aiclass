{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (2, 100)\n",
      "[[ 0.07338195  0.43612549  0.06019995  0.48423055  0.32781744  0.54140955\n",
      "   0.01094272  0.46617499  0.47100574  0.90277839  0.038757    0.79009295\n",
      "   0.94765365  0.20044595  0.54184788  0.13793017  0.41239777  0.61528927\n",
      "   0.71138114  0.14903022  0.76293731  0.80067527  0.63601667  0.38061085\n",
      "   0.16332512  0.38119546  0.09534862  0.22989888  0.50411105  0.49295929\n",
      "   0.43039274  0.57008094  0.96744287  0.74624747  0.13883011  0.57289755\n",
      "   0.74446368  0.80731261  0.54832536  0.35580471  0.06415667  0.88052386\n",
      "   0.79579079  0.11393336  0.04457105  0.22959706  0.67390275  0.10757237\n",
      "   0.45238951  0.18352683  0.64267677  0.9403379   0.98559469  0.71498674\n",
      "   0.29398513  0.17791039  0.10947058  0.60381556  0.14542434  0.40902022\n",
      "   0.05018373  0.70105243  0.71056312  0.26474011  0.7667287   0.65979236\n",
      "   0.70453548  0.35508806  0.91870588  0.94285917  0.98971266  0.48609868\n",
      "   0.66165066  0.3520636   0.6265316   0.14310108  0.80154592  0.30065653\n",
      "   0.29609326  0.44157162  0.81198311  0.04619633  0.87471765  0.65434253\n",
      "   0.99776042  0.2341325   0.37102091  0.82695293  0.29318714  0.68470061\n",
      "   0.61828923  0.95675969  0.09068809  0.66411018  0.24324192  0.2438527\n",
      "   0.82833433  0.1959469   0.76935053  0.4314132 ]\n",
      " [ 0.82523036  0.04735154  0.21578254  0.05296985  0.91090733  0.15925939\n",
      "   0.67246622  0.40822607  0.98823768  0.79584002  0.82938182  0.40530506\n",
      "   0.90369266  0.76941764  0.28980425  0.43109077  0.5619511   0.06582041\n",
      "   0.06856937  0.33466431  0.38544646  0.52034265  0.18611629  0.93980616\n",
      "   0.18761462  0.93364972  0.09375308  0.03342486  0.92694587  0.15579838\n",
      "   0.64700639  0.98527795  0.57959634  0.70925432  0.17292896  0.84758991\n",
      "   0.69670117  0.16790822  0.82076985  0.88914776  0.58835191  0.57726496\n",
      "   0.62222856  0.71534979  0.00484966  0.97387642  0.80810136  0.54032379\n",
      "   0.34429097  0.37802991  0.84528607  0.89056659  0.04143603  0.69018525\n",
      "   0.79905248  0.56571668  0.19623516  0.83914989  0.62527716  0.53238696\n",
      "   0.94964755  0.98955798  0.70040959  0.15555765  0.27453342  0.45093289\n",
      "   0.73865736  0.67614436  0.5778923   0.8514871   0.78385729  0.23633747\n",
      "   0.25727689  0.32703424  0.43420729  0.76557177  0.21024011  0.90699369\n",
      "   0.25443077  0.75654477  0.15833817  0.98720306  0.67833585  0.29785621\n",
      "   0.6232838   0.18841752  0.23027003  0.503537    0.55031163  0.129696\n",
      "   0.08467413  0.28892246  0.31513903  0.6157012   0.29902932  0.79188854\n",
      "   0.84490389  0.4935658   0.17976931  0.9399088 ]]\n",
      "<class 'numpy.ndarray'> (100,)\n",
      "[ 0.47238427  0.35308286  0.3491765   0.35901703  0.51496321  0.38599283\n",
      "  0.43558752  0.42826271  0.54474811  0.54944584  0.46975206  0.46007031\n",
      "  0.5755039   0.47392812  0.41214564  0.40001117  0.45363     0.37469301\n",
      "  0.38485199  0.38183589  0.45338302  0.48413606  0.40082493  0.52602232\n",
      "  0.35385544  0.52484949  0.32828548  0.32967486  0.53580028  0.3804556\n",
      "  0.47244055  0.55406368  0.51266356  0.51647561  0.3484688   0.52680774\n",
      "  0.5137866   0.41431291  0.51898651  0.51341002  0.42408605  0.50350538\n",
      "  0.50402479  0.45446329  0.30542704  0.51773499  0.52901055  0.418822\n",
      "  0.41409715  0.39395867  0.53332489  0.57214711  0.40684668  0.50953572\n",
      "  0.48920901  0.43093438  0.35019409  0.52821153  0.43959787  0.44737941\n",
      "  0.49494788  0.56801684  0.51113823  0.35758554  0.43157955  0.45616581\n",
      "  0.51818502  0.47073768  0.50744905  0.56458334  0.55574272  0.39587736\n",
      "  0.41762044  0.40061321  0.44949462  0.46742446  0.42220261  0.51146439\n",
      "  0.38049548  0.49546612  0.41286595  0.50206024  0.52313893  0.4250055\n",
      "  0.5244328   0.36109675  0.3831561   0.48340269  0.43938104  0.39440926\n",
      "  0.37876375  0.45346046  0.37209661  0.48955126  0.38413006  0.48276298\n",
      "  0.55181421  0.41830785  0.41288891  0.53112308]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Numpy 랜덤으로 100개의 가짜 데이터 채우기.\n",
    "x = np.float32(np.random.rand(2, 100))\n",
    "#2행 100열 데이터에 랜덤한 데이터를 가져옴\n",
    "\n",
    "# 학습 레이블(목표값)은 아래의 식으로 산출. (W = [0.1, 0.2], b = 0.3)\n",
    "y_target = np.dot([0.100, 0.200], x) + 0.300\n",
    "\n",
    "print(type(x), x.shape)\n",
    "print(x)\n",
    "print(type(y_target), y_target.shape)\n",
    "print(y_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델을 만듬 (initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1, 2)\n",
      "(1, 100)\n"
     ]
    }
   ],
   "source": [
    "# y = w1*x1 + w2*x2 + b\n",
    "# y = Wx + b (w, x는 벡터)\n",
    "\n",
    "# b는 0 으로 초기화\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "# 스칼라 1개\n",
    "\n",
    "# W는 1x2 형태의 가중치 변수, 역시 0으로 초기화\n",
    "W = tf.Variable(tf.zeros([1, 2]))\n",
    "# 1x2의 모양 안에 0을 채움\n",
    "\n",
    "# 모델 생성 --> Tenforflow Graph 완성\n",
    "y = tf.matmul(W, x) + b\n",
    "            # 1x2 , 2x100의 곱 = 1x100\n",
    "\n",
    "print(b.get_shape())\n",
    "print(W.get_shape())\n",
    "print(y.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수 정의, backpropagation 적용, 학습 목표 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 손실 함수 정의\n",
    "loss = tf.reduce_mean(tf.square(y - y_target))\n",
    "# 전체 값들의 평균 값으로 줄인 결과를 loss에 저장\n",
    "\n",
    "# 경사하강법으로 Backpropagation 적용 (0.0005는 learning rate) --> W와 b 변수 변경\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0005)\n",
    "\n",
    "# optimizer의 학습 목표 정의\n",
    "train = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.21044939756393433, w: [[ 0.00023243  0.00025738]], b: [ 0.00045461]\n",
      "step: 10000, loss: 6.545416545122862e-05, w: [[ 0.12417842  0.18548667]], b: [ 0.29552308]\n",
      "step: 20000, loss: 1.3071939065412153e-05, w: [[ 0.11129743  0.19438742]], b: [ 0.29726121]\n",
      "step: 30000, loss: 2.7075345769844716e-06, w: [[ 0.10536936  0.19796537]], b: [ 0.29833955]\n",
      "step: 40000, loss: 5.907806439608976e-07, w: [[ 0.10259994  0.19934703]], b: [ 0.29901499]\n",
      "step: 50000, loss: 1.4057542330192518e-07, w: [[ 0.10129201  0.19985324]], b: [ 0.29939935]\n",
      "step: 60000, loss: 3.4227230827355015e-08, w: [[ 0.10064228  0.19999024]], b: [ 0.29967406]\n",
      "step: 70000, loss: 9.30210219962646e-09, w: [[ 0.10033187  0.19999716]], b: [ 0.29982322]\n",
      "step: 80000, loss: 3.5466820591523174e-09, w: [[ 0.10020078  0.20000008]], b: [ 0.29988623]\n",
      "step: 90000, loss: 1.7046124511921334e-09, w: [[ 0.10013404  0.20000157]], b: [ 0.29991829]\n",
      "step: 100000, loss: 1.7046124511921334e-09, w: [[ 0.10013404  0.20000157]], b: [ 0.29991829]\n",
      "sample_x: [[0.073381945], [0.82523036]], sample_y: [[ 0.4723137]], sample_y_target: 0.4723842665553093\n",
      "sample_x: [[0.43612549], [0.047351543]], sample_y: [[ 0.35305968]], sample_y_target: 0.3530828572809696\n",
      "sample_x: [[0.060199954], [0.21578254]], sample_y: [[ 0.34910321]], sample_y_target: 0.34917650297284125\n",
      "new_x: [[1.5], [1.5]], y_value: [[ 0.75012171]]\n"
     ]
    }
   ],
   "source": [
    "# 세션 시작\n",
    "with tf.Session() as sess:\n",
    "    # 모든 변수를 초기화.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # 100000번 학습.\n",
    "    for step in range(0, 100001):\n",
    "        sess.run(train)\n",
    "        if step % 10000 == 0:\n",
    "            loss_value = sess.run(loss)\n",
    "            w_value = sess.run(W)\n",
    "            b_value = sess.run(b)\n",
    "            print(\"step: {0}, loss: {1}, w: {2}, b: {3}\".format(step, loss_value, w_value, b_value))\n",
    "    \n",
    "    print\n",
    "    \n",
    "    # 학습된 모델을 활용한 값과 실제 값 비교\n",
    "    sample_x = [[x[0][0]], [x[1][0]]] # 0번째 데이터\n",
    "    sample_y = sess.run(tf.matmul(W, sample_x) + b)\n",
    "    sample_y_target = y_target[0]\n",
    "    print(\"sample_x: {0}, sample_y: {1}, sample_y_target: {2}\".format(sample_x, sample_y, sample_y_target))\n",
    "    \n",
    "    sample_x = [[x[0][1]], [x[1][1]]] # 1번째 데이터\n",
    "    sample_y = sess.run(tf.matmul(W, sample_x) + b)\n",
    "    sample_y_target = y_target[1]\n",
    "    print(\"sample_x: {0}, sample_y: {1}, sample_y_target: {2}\".format(sample_x, sample_y, sample_y_target))\n",
    "    \n",
    "    sample_x = [[x[0][2]], [x[1][2]]] # 2번째 데이터\n",
    "    sample_y = sess.run(tf.matmul(W, sample_x) + b)\n",
    "    sample_y_target = y_target[2]\n",
    "    print(\"sample_x: {0}, sample_y: {1}, sample_y_target: {2}\".format(sample_x, sample_y, sample_y_target))\n",
    "    \n",
    "    print\n",
    "    \n",
    "    # 학습된 모델을 활용한 새로운 데이터 값에 대한 y 값 예측\n",
    "    new_x = [[1.5], [1.5]]\n",
    "    y_value = sess.run(tf.matmul(W, new_x) + b)\n",
    "    print(\"new_x: {0}, y_value: {1}\".format(new_x, y_value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
