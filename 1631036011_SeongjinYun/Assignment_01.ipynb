{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.zeros((2,2)); b = tf.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_sum(b, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(2)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reshape(a,(1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=np.zeros((2,2)); ta= tf.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros_1:0\", shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run (ta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computatiobn Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= tf.constant(5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b= tf.constant(6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFLow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.zeros((2,2)), name =\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value weight\n\t [[Node: _send_weight_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-1769689113212532674, tensor_name=\"weight:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](weight)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value weight\n\t [[Node: _send_weight_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-1769689113212532674, tensor_name=\"weight:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](weight)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c0b42a6ce16b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value weight\n\t [[Node: _send_weight_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-1769689113212532674, tensor_name=\"weight:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](weight)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([5,2,], stddev=0.1),name =\"witght\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02966132 -0.03904483]\n",
      " [ 0.00878909 -0.00720897]\n",
      " [-0.03406881  0.09977693]\n",
      " [ 0.06237019  0.04492413]\n",
      " [-0.01883761  0.0438494 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = tf.Variable(0, name=\"counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_value = tf.add(state, tf.constant(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update = tf.assign(state, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = tf.constant(1)\n",
    ">>> x2 = tf.constant(2)\n",
    ">>> x3 = tf.constant(3)\n",
    ">>> temp = tf.add(x2, x3)\n",
    ">>> mul = tf.multiply(x1, temp)##현재 텐서플로우 모듈에는 mul이 없음, 아마 multiply로 바뀌었을것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result1, result2 = sess.run([mul, temp])\n",
    "    print(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    ">>> a = tf.placeholder(tf.int16)\n",
    ">>> b = tf.placeholder(tf.int16)\n",
    ">>> add = tf.add(a, b)\n",
    ">>> mul = tf.multiply(a, b)\n",
    ">>> with tf.Session() as sess:\n",
    ">>>  print(sess.run(add, feed_dict={a: 2, b: 3}))\n",
    ">>>  print(sess.run(mul, feed_dict={a: 2, b: 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n",
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "# using tf.constant\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)\n",
    "# using placeholder\n",
    "import numpy as np\n",
    "matrix1 = tf.placeholder(tf.float32, [1, 2])\n",
    "matrix2 = tf.placeholder(tf.float32, [2, 1])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "with tf.Session() as sess:\n",
    "    mv1 = np.array([[3., 3.]])\n",
    "    mv2 = np.array([[2.], [2.]])\n",
    "    result = sess.run(product, feed_dict={matrix1: mv1, matrix2: mv2})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example - MNIST with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\",\n",
    "one_hot=True)\n",
    "learning_rate = 0.001\n",
    "max_steps = 15000\n",
    "batch_size = 128\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MLP(inputs):\n",
    "    W_1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "    b_1 = tf.Variable(tf.zeros([256]))\n",
    "    W_2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "    b_2 = tf.Variable(tf.zeros([256]))\n",
    "    W_out = tf.Variable(tf.random_normal([256, 10]))\n",
    "    b_out = tf.Variable(tf.zeros([10]))\n",
    "    h_1 = tf.add(tf.matmul(inputs, W_1), b_1)\n",
    "    h_1 = tf.nn.relu(h_1)\n",
    "    h_2 = tf.add(tf.matmul(h_1, W_2), b_2)\n",
    "    h_2 = tf.nn.relu(h_2)\n",
    "    out = tf.add(tf.matmul(h_2, W_out), b_out)\n",
    "    return out\n",
    "net = MLP(x)\n",
    "# define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = net,labels  = y))\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15000/15000] loss:0.000\n",
      "Optimization Finished!\n",
      "Train accuracy: 0.997\n",
      "Test accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "# initializing the variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "# train model\n",
    "for step in range(max_steps):\n",
    "    batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
    "    _, loss = sess.run([opt, loss_op],\n",
    "        feed_dict={x: batch_X, y: batch_y})\n",
    "if (step+1) % 1000 == 0:\n",
    "    print(\"[{}/{}] loss:{:.3f}\".format(step+1, max_steps, loss))\n",
    "print(\"Optimization Finished!\")\n",
    "# test model\n",
    "correct_prediction = tf.equal(tf.argmax(net, 1), tf.argmax(y, 1))\n",
    "# calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Train accuracy: {:.3f}\" .format(sess.run(accuracy, feed_dict={x: mnist.train.images, y: mnist.train.labels})))\n",
    "print(\"Test accuracy: {:.3f}\" .format(sess.run(accuracy,feed_dict={x: mnist.test.images, y: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Variable Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tf.variable_scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: var:0\n",
      "var2: foo/bar/var:0\n",
      "var3: foo/bar/var_1:0\n"
     ]
    }
   ],
   "source": [
    "var1 = tf.Variable([1], name=\"var\")\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.variable_scope(\"bar\"):\n",
    "        var2 = tf.Variable([1], name=\"var\")\n",
    "        var3 = tf.Variable([1], name=\"var\")\n",
    "        \n",
    "print(\"var1: {}\".format(var1.name))\n",
    "print(\"var2: {}\".format(var2.name))\n",
    "print(\"var3: {}\".format(var3.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.get_variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: var_1:0\n",
      "var2: foo_1/bar/var:0\n",
      "var3: foo_1/bar/var_1:0\n"
     ]
    }
   ],
   "source": [
    "var1 = tf.Variable([1], name=\"var\")\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.variable_scope(\"bar\") as scp:\n",
    "        var2 = tf.Variable([1], name=\"var\")\n",
    "        scp.reuse_variables() # allow reuse variables\n",
    "        var3 = tf.Variable([1], name=\"var\")\n",
    "print(\"var1: {}\".format(var1.name))\n",
    "print(\"var2: {}\".format(var2.name))\n",
    "print(\"var3: {}\".format(var3.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: foo/bar/var_2:0\n",
      "var2: foo/bar/var_2:0\n",
      "var3: foo/bar/var_2:0\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.variable_scope(\"bar\") as scp:\n",
    "        var1 = tf.get_variable(\"var\", [1])\n",
    "        scp.reuse_variables()\n",
    "        var2 = tf.get_variable(\"var\", [1])\n",
    "    with tf.variable_scope(\"bar\", reuse=True):\n",
    "        var3 = tf.get_variable(\"var\", [1])\n",
    "print(\"var1: {}\".format(var1.name))\n",
    "print(\"var2: {}\".format(var2.name))\n",
    "print(\"var3: {}\".format(var3.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 변수 접근시에 tf.getvariable을 사용!\n",
    "##### tf.Variable은 parameter sharing을 제공하지 않고, initializer와 regularizer를 사용할 수 없음므"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import variance_scaling_initializer\n",
    "he_init = variance_scaling_initializer()\n",
    "def conv(bottom, num_filter, ksize=3, stride=1, padding=\"SAME\",scope=None):\n",
    "    bottom_shape = bottom.get_shape().as_list()[3]\n",
    "    with tf.variable_scope(scope or \"conv\"):\n",
    "        W = tf.get_variable(\"W\",\n",
    "            [ksize, ksize, bottom_shape, num_filter],\n",
    "            initializer=he_init)\n",
    "        b = tf.get_variable(\"b\", [num_filter],\n",
    "            initializer=tf.constant_initializer(0))\n",
    "        x = tf.nn.conv2d(bottom, W,\n",
    "            strides=[1, stride, stride, 1],\n",
    "            padding=padding)\n",
    "        x = tf.nn.relu(tf.nn.bias_add(x, b))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maxpool(bottom,\n",
    "            ksize=2, stride=2, padding=\"SAME\",\n",
    "            scope=None):\n",
    "    with tf.variable_scope(scope or \"maxpool\"):\n",
    "        pool = tf.nn.max_pool(bottom, ksize=[1, ksize, ksize, 1],\n",
    "                                strides=[1, stride, stride, 1],\n",
    "                                padding=padding)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(bottom, num_dims, scope=None):\n",
    "    bottom_shape = bottom.get_shape().as_list()\n",
    "    if len(bottom_shape) > 2:\n",
    "        bottom = tf.reshape(bottom,\n",
    "                                [-1, reduce(lambda x, y: x*y, bottom_shape[1:])])\n",
    "        bottom_shape = bottom.get_shape().as_list()\n",
    "    with tf.variable_scope(scope or \"fc\"):\n",
    "        W = tf.get_variable(\"W\", [bottom_shape[1], num_dims],\n",
    "                                                initializer=he_init)\n",
    "        b = tf.get_variable(\"b\", [num_dims],\n",
    "                                            initializer=tf.constant_initializer(0))\n",
    "        out = tf.nn.bias_add(tf.matmul(bottom, W), b)\n",
    "    return out\n",
    "def fc_relu(bottom, num_dims, scope=None):\n",
    "    with tf.variable_scope(scope or \"fc\"):\n",
    "        out = fc(bottom, num_dims, scope=\"fc\")\n",
    "        relu = tf.nn.relu(out)\n",
    "    return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32, None)\n",
    "def conv_net(x, keep_prob):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    conv1 = conv(x, 32, 5, scope=\"conv_1\")\n",
    "    conv1 = maxpool(conv1, scope=\"maxpool_1\")\n",
    "    conv2 = conv(conv1, 64, 5, scope=\"conv_2\")\n",
    "    conv2 = maxpool(conv2, scope=\"maxpool_2\")\n",
    "    fc1 = fc_relu(conv2, 1024, scope=\"fc_1\")\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    out = fc(fc1, 10, scope=\"out\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32, None)\n",
    "def conv_net(x, keep_prob):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    conv1 = conv(x, 32, 5, scope=\"conv_1\")\n",
    "    conv1 = maxpool(conv1, scope=\"maxpool_1\")\n",
    "    conv2 = conv(conv1, 64, 5, scope=\"conv_2\")\n",
    "    conv2 = maxpool(conv2, scope=\"maxpool_2\")\n",
    "    fc1 = fc_relu(conv2, 1024, scope=\"fc_1\")\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    out = fc(fc1, 10, scope=\"out\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape(tensor):\n",
    "    s = tensor.get_shape().r\n",
    "    return tuple([s[i].value for i in range(0, len(s))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "input = tf.Variable(tf.truncated_normal([1,128,128,1]))\n",
    "\n",
    "with tf.name_scope('conv1_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([1, 1, 1, 1],\n",
    "            dtype=tf.float32, stddev=1e-1),\n",
    "    name='weights')\n",
    "    conv = tf.nn.conv2d(input, kernel, [1,1,1,1],padding='SAME')\n",
    "    print(shape(conv))\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[1],dtype=tf.float32), trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(value = conv, bias = biases)\n",
    "    conv1 = tf.nn.relu(bias, name=scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input의 Last dimension의 크기와 biases의 shape를 맞춰줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(tf.Variable(tf.constant(0.0, shape=[128],dtype=tf.float32), trainable=True, name='biases'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializer, REgularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-2fe761ba6e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m net = slim.conv2d(inputs, 64, [11, 11], 4, padding='SAME',\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mweights_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mweights_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_regularizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     scope='conv1')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slim' is not defined"
     ]
    }
   ],
   "source": [
    "net = slim.conv2d(inputs, 64, [11, 11], 4, padding='SAME',\n",
    "    weights_initializer=slim.xavier_initializer(),\n",
    "    weights_regularizer=slim.l2_regularizer(0.0005),\n",
    "    scope='conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### argscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-26e1144daf35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhe_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance_scaling_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxavier_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m with slim.arg_scope([slim.conv2d, slim.fully_connected],\n\u001b[1;32m      4\u001b[0m                     \u001b[0mactivation_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mweights_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhe_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slim' is not defined"
     ]
    }
   ],
   "source": [
    "he_init = slim.variance_scaling_initializer()\n",
    "xavier_init = slim.xavier_initializer()\n",
    "with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                    activation_fn=tf.nn.relu,\n",
    "                    weights_initializer=he_init,\n",
    "                    weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "    with slim.arg_scope([slim.conv2d], stride=1, padding='SAME'):\n",
    "        net = slim.conv2d(inputs, 64, [11, 11], 4, scope='conv1')\n",
    "        net = slim.conv2d(net, 256, [5, 5],\n",
    "                            weights_initializer=xavier_init,\n",
    "                            scope='conv2')\n",
    "    net = slim.fully_connected(net, 1000,\n",
    "                activation_fn=None, scope='fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-72120cab3924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Define the loss functions and get the total loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# The following two lines have the same effect:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slim' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the loss functions and get the total loss.\n",
    "loss1 = slim.losses.softmax_cross_entropy(pred1, label1)\n",
    "loss2 = slim.losses.mean_squared_error(pred2, label2)\n",
    "# The following two lines have the same effect:\n",
    "total_loss = loss1 + loss2\n",
    "slim.losses.get_total_loss(add_regularization_losses=False)\n",
    "# If you want to add regularization loss\n",
    "reg_loss = tf.add_n(slim.losses.get_regularization_losses())\n",
    "total_loss = loss1 + loss2 + reg_loss\n",
    "# or\n",
    "total_loss = slim.losses.get_total_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slim 변수 선언부가 pdf에 없어서 코드만 쳐보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-e56530c9b927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mdef\u001b[0m \u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_collection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloss_collection\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_collection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ops' is not defined"
     ]
    }
   ],
   "source": [
    "def add_loss(loss, loss_collection=ops.GraphKeys.LOSSES):\n",
    "    if loss_collection:\n",
    "        ops.add_to_collection(loss_collection, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-5fcb5342526b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mdef\u001b[0m \u001b[0mget_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_collection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_collection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_regularization_lossses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGrapthKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREGULARIZATION_LOSSES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ops' is not defined"
     ]
    }
   ],
   "source": [
    "def get_losses(scope=None, loss_collection=ops.GraphKeys.LOSSES):\n",
    "    return ops.get_collection(loss_collection, scope)\n",
    "\n",
    "def get_regularization_lossses(scope=None):\n",
    "    return ops.get_collection(ops.GrapthKeys.REGULARIZATION_LOSSES,scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'trainable_variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-9cb1683f93c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrainable_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_colection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'trainable_variable'"
     ]
    }
   ],
   "source": [
    "for var in tf.trainable_variable():\n",
    "    print(var.name)\n",
    "    \n",
    "def trainable_variable():\n",
    "    return ops.get_colection(ops.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ops가 정의된 부분이 없어서 실행 불가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_latest_checkpoint(self, ckpt_dir, exclude=None):\n",
    "    path = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    if path is None:\n",
    "        raise AssertionError(\"No ckpt exists in {0}.\".format(ckpt_dir))\n",
    "    print(\"Load {} save file\".format(path))\n",
    "    self._load(path, exclude)\n",
    "def load_from_path(self, ckpt_path, exclude=None):\n",
    "    self._load(ckpt_path, exclude)\n",
    "def _load(self, ckpt_path, exclude):\n",
    "    init_fn = slim.assign_from_checkpoint_fn(ckpt_path,\n",
    "    slim.get_variables_to_restore(exclude=exclude),\n",
    "    ignore_missing_vars=True)\n",
    "    init_fn(self.config[\"sess\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_16(inputs, num_classes=1000, is_training=True, dropout_keep_prob=0.5, spatial_squeeze=True, scope='vgg_16'):\n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], ouputs_collection=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2,2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2,2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2,2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2,2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2,2], scope='pool5')\n",
    "            net = slim.conv2d(net, 4096, [7,7], padding='VALID', scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope = 'dropout6')\n",
    "            net = slim.conv2d(net, 4096, [1,1], padding='VALID', scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope = 'dropout7')\n",
    "            net = slim.conv2d(net, num_classes, [1,1], activation_fn=None, normalizer_fn=None, scope='fc8')\n",
    "            \n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "            if spatial_squeeze:\n",
    "                net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "                end_points[sc.name+'/fc8'] = net\n",
    "            return net, end_points\n",
    "    vgg_16.default_image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_arg_scope(weight_decay=0.0005):\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected], activation_fn=tf.nn.relu, weights_regularize=slim.l2_regularizer(weight_decay), biases_initializer=tf.zeros_initializer):\n",
    "        with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:\n",
    "            return arg_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-949e4c6afc1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"is_training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;32mwith\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg_arg_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_pts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg_16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"losses\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slim' is not defined"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 224, 224, 3], name=\"X\")\n",
    "y = tf.placeholder(tf.int32, [None, 8], name=\"y\")\n",
    "is_training = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()): net, end_pts = vgg.vgg_16(X, is_training=is_training, num_classes=1000)\n",
    "\n",
    "with tf.variable_scope(\"losses\"):\n",
    "    cls_loss = slim.losses.softmax_cross_entropy(net, y)\n",
    "    reg_loss = tf.add_n(slim.losses.get_regularization_losses())\n",
    "    loss_op = type_loss + reg_loss\n",
    "\n",
    "with tf.variable_scope(\"opt\"):\n",
    "    opt = tf.train.AdamOptimizer(0.001).minimize(loss_op)\n",
    "    \n",
    "self.load_from_path(ckpt_path=VGG_PATH, exclude=[\"vgg_16/fc8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard & slim example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "max_steps = 10000\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "keep_prob = 0.5\n",
    "weight_decay = 0.0004\n",
    "logs_path = \"/tmp/tensorflow_logs/example\"\n",
    "def my_arg_scope(is_training, weight_decay):\n",
    "    with slim.arg_scope([slim.conv2d],\n",
    "        activation_fn=tf.nn.relu,\n",
    "        weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "        weights_initializer=slim.variance_scaling_initializer(),\n",
    "        biases_initializer=tf.zeros_initializer,\n",
    "        stride=1, padding=\"SAME\"):\n",
    "        with slim.arg_scope([slim.dropout],\n",
    "                is_training=is_training) as arg_sc:\n",
    "            return arg_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_net(x, keep_prob, outputs_collections=\"my_net\"): \n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1]) \n",
    "    \n",
    "    with slim.arg_scope([slim.conv2d, slim.max_pool2d], \n",
    "                        outputs_collections=outputs_collections): \n",
    "        net = slim.conv2d(x, 64, [3, 3], scope=\"conv1\") \n",
    "        net = slim.max_pool2d(net, [2, 2], scope=\"pool1\") \n",
    "        net = slim.conv2d(net, 128, [3, 3], scope=\"conv2\") \n",
    "        net = slim.max_pool2d(net, [2, 2], scope=\"pool2\") \n",
    "        net = slim.conv2d(net, 256, [3, 3], scope=\"conv3\") \n",
    "        # global average pooling \n",
    "        net = tf.reduce_mean(net, [1, 2], name=\"pool3\", keep_dims=True) \n",
    "        net = slim.dropout(net, keep_prob, scope=\"dropout3\") \n",
    "        net = slim.conv2d(net, 1024, [1, 1], scope=\"fc4\") \n",
    "        net = slim.dropout(net, keep_prob, scope=\"dropout4\") \n",
    "        net = slim.conv2d(net, 10, [1, 1], \n",
    "                          activation_fn=None, scope=\"fc5\") \n",
    "        \n",
    "        end_points = \\\n",
    "        slim.utils.convert_collection_to_dict(outputs_collections) \n",
    "        \n",
    "        return tf.reshape(net, [-1, 10]), end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-3f90d2eb0179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_arg_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_pts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-93c285505e99>\u001b[0m in \u001b[0;36mmy_net\u001b[0;34m(x, keep_prob, outputs_collections)\u001b[0m\n\u001b[1;32m      4\u001b[0m     with slim.arg_scope([slim.conv2d, slim.max_pool2d], \n\u001b[1;32m      5\u001b[0m                         outputs_collections=outputs_collections): \n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"conv1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pool1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"conv2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_key_op'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m    905\u001b[0m                         \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                         _reuse=reuse)\n\u001b[0;32m--> 907\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[1;31m# Add variables to collections.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    143\u001b[0m                                   \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                                   \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                                   dtype=self.dtype)\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    986\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m       custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    989\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m    990\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m           custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    339\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m           validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m       return _true_getter(\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mvariable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           variable_getter=functools.partial(getter, **kwargs))\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[1;31m# Build (if necessary) and call the layer, inside a variable scope.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m_add_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, variable_getter)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                                trainable=trainable and self.trainable)\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[1;31m# TODO(sguada) fix name = variable.op.name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexisting_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[0;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0mgetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_custom_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rename'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, **_)\u001b[0m\n\u001b[1;32m   1297\u001b[0m       \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m       \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m       custom_getter=getter)\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_key_op'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter)\u001b[0m\n\u001b[1;32m    266\u001b[0m                  \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                  \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                  partitioner=partitioner, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    269\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_key_op'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter)\u001b[0m\n\u001b[1;32m    223\u001b[0m                   \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                   \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                   partitioner=partitioner)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m           caching_device=caching_device, validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariable_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    685\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     logging.vlog(1, \"Created variable %s with shape %s and init %s\", v.name,\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope)\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m           expected_shape=expected_shape)\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m               self._initial_value = ops.convert_to_tensor(\n\u001b[0;32m--> 274\u001b[0;31m                   initial_value(), name=\"initial_value\", dtype=dtype)\n\u001b[0m\u001b[1;32m    275\u001b[0m               shape = (self._initial_value.get_shape()\n\u001b[1;32m    276\u001b[0m                        if validate_shape else tensor_shape.unknown_shape())\n",
      "\u001b[0;32mC:\\Users\\smartCPS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    671\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         init_val = lambda: initializer(\n\u001b[0;32m--> 673\u001b[0;31m             shape.as_list(), dtype=dtype, partition_info=partition_info)\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0mvariable_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'dtype'"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "y = tf.placeholder(tf.float32, [None, 10]) \n",
    "is_training = tf.placeholder(tf.bool) \n",
    "\n",
    "with slim.arg_scope(my_arg_scope(is_training, weight_decay)): \n",
    "    net, end_pts = my_net(x, keep_prob) \n",
    "    pred = slim.softmax(net, scope=\"prediction\") \n",
    "    \n",
    "with tf.variable_scope(\"losses\"): \n",
    "    cls_loss = slim.losses.softmax_cross_entropy(net, y) \n",
    "    reg_loss = tf.add_n(slim.losses.get_regularization_losses()) \n",
    "    loss_op = cls_loss + reg_loss \n",
    "        \n",
    "with tf.variable_scope(\"Adam\"): \n",
    "    opt = tf.train.AdamOptimizer(lr) \n",
    "    # Op to calculate every variable gradient \n",
    "    grads = tf.gradients(loss_op, tf.trainable_variables()) \n",
    "    grads = list(zip(grads, tf.trainable_variables())) \n",
    "    # Op to update all variables according to their gradient \n",
    "    apply_grads = opt.apply_gradients(grads_and_vars=grads) \n",
    "            \n",
    "with tf.variable_scope(\"accuracy\"): \n",
    "    correct_op = tf.equal(tf.argmax(net, 1), tf.argmax(y, 1)) \n",
    "    acc_op = tf.reduce_mean(tf.cast(correct_op, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_op' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-af4fa5e99abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msumm_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msumm_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy_test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"my_summ\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_op' is not defined"
     ]
    }
   ],
   "source": [
    "summ_loss = tf.summary.scalar(\"loss\", loss_op)\n",
    "summ_acc = tf.summary.scalar(\"accuracy_test\", acc_op)\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.name, var, collections=[\"my_summ\"])\n",
    "for grad, var in grads:\n",
    "    tf.summary.histogram(var.name + \"/gradient\", grad,\n",
    "\n",
    "collections=[\"my_summ\"])\n",
    "summ_wg = tf.summary.merge_all(key=\"my_summ\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=sess.graph)\n",
    "for step in range(max_steps):\n",
    "    batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
    "    _, loss, plot_loss, plot_wg = sess.run([apply_grads, loss_op, \n",
    "                                            summ_loss, summ_wg], \n",
    "    feed_dict={x: batch_X, y: batch_y, is_training: True}) \n",
    "    summary_writer.add_summary(plot_loss, step)\n",
    "    summary_writer.add_summary(plot_wg, step)\n",
    "    if (step+1) % 100 == 0:\n",
    "        plot_acc = sess.run(summ_acc, feed_dict={x: mnist.test.images, y: mnist.test.labels, is_training: False})\n",
    "    summary_writer.add_summary(plot_acc, step)\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "test_acc = sess.run(acc_op, feed_dict={x: mnist.test.images, y: mnist.test.labels, is_training: False})\n",
    "\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
