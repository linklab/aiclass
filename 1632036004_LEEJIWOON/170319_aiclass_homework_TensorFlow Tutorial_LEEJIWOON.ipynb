{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if you know Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((2,2)); b = np.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(b,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.reshape(a,(1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.zeros((2,2)); b = tf.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.reduce_sum(b, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.reshape(a,(1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "a = np.zeros((2,2)); ta = tf.zeros((2,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(ta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess =  tf.Session()\n",
    "print(sess.run(c))\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorFlow Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.zeros((2,2)), name=\"weight\")\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables need initializtion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w =  tf.Variable(tf.random_normal([5,2,], stddev=0.1), name=\"weight\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "new_value = tf.add(state, tf.constant(1))\n",
    "update = tf.assign(state, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = tf.constant(1)\n",
    "x2 = tf.constant(2)\n",
    "x3 = tf.constant(3)\n",
    "temp = tf.add(x2, x3)\n",
    "mul = tf.multiply(x1, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result1, result2 = sess.run([mul, temp])\n",
    "    print(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add = tf.add(a,b)\n",
    "mul = tf.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session () as sess:\n",
    "    print(sess.run(add, feed_dict={a: 2, b: 3}))\n",
    "    print(sess.run(mul, feed_dict={a: 2, b: 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using tf.constant\n",
    "matrix1 = tf.constant([[3.,3.]])\n",
    "matrix2 = tf.constant([[2.], [2.]])\n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using placesolder\n",
    "import numpy as np\n",
    "\n",
    "matrix1 = tf.placeholder(tf.float32, [1, 2])\n",
    "matrix2 = tf.placeholder(tf.float32, [2, 1])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    mv1 = np.array([[3., 3.]])\n",
    "    mv2 = np.array([[2.], [2.]])\n",
    "    result = sess.run(product, feed_dict={matrix1: mv1, matrix2: mv2})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "# Import MINST data \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True) \n",
    "\n",
    "learning_rate = 0.001 \n",
    "max_steps = 15000 \n",
    "batch_size = 128 \n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "y = tf.placeholder(tf.float32, [None, 10]) \n",
    "\n",
    "def MLP(inputs): \n",
    "    W_1 = tf.Variable(tf.random_normal([784, 256])) \n",
    "    b_1 = tf.Variable(tf.zeros([256])) \n",
    "    \n",
    "    W_2 = tf.Variable(tf.random_normal([256, 256])) \n",
    "    b_2 = tf.Variable(tf.zeros([256])) \n",
    "    \n",
    "    W_out = tf.Variable(tf.random_normal([256, 10])) \n",
    "    b_out = tf.Variable(tf.zeros([10])) \n",
    "    \n",
    "    h_1 = tf.add(tf.matmul(inputs, W_1), b_1) \n",
    "    h_1 = tf.nn.relu(h_1) \n",
    "    \n",
    "    h_2 = tf.add(tf.matmul(h_1, W_2), b_2) \n",
    "    h_2 = tf.nn.relu(h_2) \n",
    "    \n",
    "    out = tf.add(tf.matmul(h_2, W_out), b_out) \n",
    "    \n",
    "    return out \n",
    "\n",
    "net = MLP(x) \n",
    "\n",
    "# define loss and optimizer \n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net, y)) \n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(loss_op)\n",
    "\n",
    "# initializing the variables\n",
    "init_op = tf.global_variables_initializer() \n",
    "\n",
    "sess = tf.Session() \n",
    "sess.run(init_op) \n",
    "\n",
    "# train model \n",
    "for step in range(max_steps): \n",
    "    batch_X, batch_y = mnist.train.next_batch(batch_size) \n",
    "    _, loss = sess.run([opt, loss_op], feed_dict={x: batch_X, y: batch_y}) \n",
    "    \n",
    "    if (step+1) % 1000 == 0:\n",
    "        print(\"[{}/{}] loss:{:.3f}\".format(step+1, max_steps, loss)) \n",
    "        print(\"Optimization Finished!\")\n",
    "        \n",
    "# test model \n",
    "correct_prediction = tf.equal(tf.argmax(net, 1), tf.argmax(y, 1)) \n",
    "\n",
    "# calculate accuracy \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
    "print(\"Train accuracy: {:.3f}” .format(sess.run(accuracy, \n",
    "      feed_dict={x: mnist.train.images, y: mnist.train.labels}))) \n",
    "print(\"Test accuracy: {:.3f}” .format(sess.run(accuracy, \n",
    "      feed_dict={x: mnist.test.images, y: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.variable_scope()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var1 = tf.Variable([1], name=\"var\")\n",
    "with tf.variable_scope(\"foo\"): \n",
    "    with tf.variable_scope(\"bar\"): \n",
    "        var2 = tf.Variable([1], name=\"var\") \n",
    "        var3 = tf.Variable([1], name=\"var\") \n",
    "print(\"var1: {}\".format(var1.name)) \n",
    "print(\"var2: {}\".format(var2.name)) \n",
    "print(\"var3: {}\".format(var3.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.get_variable() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var1 = tf.Variable([1], name=\"var\") \n",
    "with tf.variable_scope(\"foo\"): \n",
    "    with tf.variable_scope(\"bar\") as scp: \n",
    "        var2 = tf.Variable([1], name=\"var\") \n",
    "        scp.reuse_variables() # allow reuse variables \n",
    "        var3 = tf.Variable([1], name=\"var\") \n",
    "        print(\"var1: {}\".format(var1.name)) \n",
    "        print(\"var2: {}\".format(var2.name)) \n",
    "        print(\"var3: {}\".format(var3.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var1 = tf.Variable([1], name=\"var\") \n",
    "with tf.variable_scope(\"foo\"): \n",
    "    with tf.variable_scope(\"bar\") as scp: \n",
    "        var2 = tf.Variable([1], name=\"var\") \n",
    "        scp.reuse_variables() # allow reuse variables\n",
    "        var3 = tf.Variable([1], name=\"var\") \n",
    "        print(\"var1: {}\".format(var1.name)) \n",
    "        print(\"var2: {}\".format(var2.name)) \n",
    "        print(\"var3: {}\".format(var3.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\"): \n",
    "    with tf.variable_scope(\"bar\") as scp: \n",
    "        var1 = tf.get_variable(\"var\", [1]) \n",
    "        scp.reuse_variables() \n",
    "        var2 = tf.get_variable(\"var\", [1]) \n",
    "        \n",
    "        with tf.variable_scope(\"bar\", reuse=True): \n",
    "            var3 = tf.get_variable(\"var\", [1]) \n",
    "            \n",
    "            print(\"var1: {}\".format(var1.name)) \n",
    "            print(\"var2: {}\".format(var2.name)) \n",
    "            print(\"var3: {}\".format(var3.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import variance_scaling_initializer \n",
    "he_init = variance_scaling_initializer() \n",
    "\n",
    "def conv(bottom, \n",
    "         num_filter, ksize=3, stride=1, padding=\"SAME\", \n",
    "         scope=None): \n",
    "    bottom_shape = bottom.get_shape().as_list()[3] \n",
    "    \n",
    "    with tf.variable_scope(scope or \"conv\"): \n",
    "        W = tf.get_variable(\"W\", \n",
    "                            [ksize, ksize, bottom_shape, num_filter], initializer=he_init) \n",
    "        b = tf.get_variable(\"b\", [num_filter], \n",
    "                            initializer=tf.constant_initializer(0)) \n",
    "        \n",
    "        x = tf.nn.conv2d(bottom, W, strides=[1, stride, stride, 1], \n",
    "                         padding=padding) \n",
    "        x = tf.nn.relu(tf.nn.bias_add(x, b)) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool(bottom, \n",
    "            ksize=2, stride=2, padding=\"SAME\", \n",
    "            scope=None): \n",
    "    \n",
    "    with tf.variable_scope(scope or \"maxpool\"): \n",
    "        pool = tf.nn.max_pool(bottom, ksize=[1, ksize, ksize, 1], \n",
    "                              strides=[1, stride, stride, 1], \n",
    "                              padding=padding) \n",
    "        \n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(bottom, num_dims, scope=None): \n",
    "    \n",
    "    bottom_shape = bottom.get_shape().as_list() \n",
    "    if len(bottom_shape) > 2: \n",
    "        bottom = tf.reshape(bottom, [-1, reduce(lambda x, y: x*y, bottom_shape[1:])]) \n",
    "        bottom_shape = bottom.get_shape().as_list() \n",
    "        \n",
    "        with tf.variable_scope(scope or \"fc\"): \n",
    "            W = tf.get_variable(\"W\", [bottom_shape[1], num_dims], \n",
    "                                initializer=he_init) \n",
    "            b = tf.get_variable(\"b\", [num_dims], \n",
    "                                initializer=tf.constant_initializer(0)) \n",
    "            out = tf.nn.bias_add(tf.matmul(bottom, W), b) \n",
    "            return out\n",
    "        \n",
    "        def fc_relu(bottom, num_dims, scope=None): \n",
    "            with tf.variable_scope(scope or \"fc\"): \n",
    "                out = fc(bottom, num_dims, scope=\"fc\") \n",
    "                relu = tf.nn.relu(out) \n",
    "                return relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32, None) \n",
    "\n",
    "def conv_net(x, keep_prob): \n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1]) \n",
    "    \n",
    "    conv1 = conv(x, 32, 5, scope=\"conv_1\") \n",
    "    conv1 = maxpool(conv1, scope=\"maxpool_1\") \n",
    "    conv2 = conv(conv1, 64, 5, scope=\"conv_2\") \n",
    "    conv2 = maxpool(conv2, scope=\"maxpool_2\") \n",
    "    \n",
    "    fc1 = fc_relu(conv2, 1024, scope=\"fc_1\") \n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob) \n",
    "    \n",
    "    out = fc(fc1, 10, scope=\"out\") \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(allow_growth=True)) \n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = ... \n",
    "with tf.name_scope('conv1_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], \n",
    "                                             dtype=tf.float32, stddev=1e-1), name='weights') \n",
    "    conv = tf.nn.conv2d(input, kernel, [1, 1, 1, 1], \n",
    "                        padding='SAME') \n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], \n",
    "                                     dtype=tf.float32), trainable=True, \n",
    "                         name='biases') \n",
    "    bias = tf.nn.bias_add(conv, biases) \n",
    "    conv1 = tf.nn.relu(bias, name=scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. simple network generation with slim \n",
    "net = ... net = slim.conv2d(net, 256, [3, 3], scope='conv3_1') \n",
    "net = slim.conv2d(net, 256, [3, 3], scope='conv3_2') \n",
    "net = slim.conv2d(net, 256, [3, 3], scope='conv3_3')\n",
    "net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "                      \n",
    "# 1. cleaner by repeat operation: \n",
    "net = ... \n",
    "net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3') \n",
    "net = slim.max_pool(net, [2, 2], scope=‘pool'3')\n",
    "\n",
    "# 2. Verbose way: \n",
    "x = slim.fully_connected(x, 32, scope='fc/fc_1') \n",
    "x = slim.fully_connected(x, 64, scope='fc/fc_2') \n",
    "x = slim.fully_connected(x, 128, scope='fc/fc_3')\n",
    "\n",
    "# 2. Equivalent, TF-Slim way using slim.stack: \n",
    "slim.stack(x, slim.fully_connected, [32, 64, 128], scope='fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializer, Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = slim.conv2d(inputs, 64, [11, 11], 4, padding='SAME',\n",
    "                  weights_initializer=slim.xavier_initializer(), \n",
    "                  weights_regularizer=slim.l2_regularizer(0.0005), \n",
    "                  scope='conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# argscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "he_init = slim.variance_scaling_initializer() \n",
    "xavier_init = slim.xavier_initializer() \n",
    "\n",
    "with slim.arg_scope([slim.conv2d, slim.fully_connected], \n",
    "                    activation_fn=tf.nn.relu, \n",
    "                    weights_initializer=he_init, \n",
    "                    weights_regularizer=slim.l2_regularizer(0.0005)): \n",
    "    with slim.arg_scope([slim.conv2d], stride=1, padding='SAME'): \n",
    "        net = slim.conv2d(inputs, 64, [11, 11], 4, scope='conv1') \n",
    "        net = slim.conv2d(net, 256, [5, 5], \n",
    "                          weights_initializer=xavier_init, \n",
    "                          scope='conv2') \n",
    "        \n",
    "        net = slim.fully_connected(net, 1000, \n",
    "                                   activation_fn=None, scope='fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save(self, ckpt_dir, global_step=None): \n",
    "    if self.config.get(\"saver\") is None: \n",
    "        self.config[\"saver\"] = \\ \n",
    "            tf.train.Saver(max_to_keep=30) \n",
    "            \n",
    "            saver = self.config[\"saver\"] \n",
    "            sess = self.config[\"sess\"] \n",
    "            \n",
    "            dirname = os.path.join(ckpt_dir, self.name) \n",
    "            \n",
    "            if not os.path.exists(dirname): \n",
    "                os.makedirs(dirname) \n",
    "                saver.save(sess, dirname, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_latest_checkpoint(self, ckpt_dir, exclude=None): \n",
    "    path = tf.train.latest_checkpoint(ckpt_dir) \n",
    "    if path is None: \n",
    "        raise AssertionError(\"No ckpt exists in {0}.\".format(ckpt_dir))\n",
    "        \n",
    "        print(\"Load {} save file\".format(path)) \n",
    "        self._load(path, exclude) \n",
    "        \n",
    "def load_from_path(self, ckpt_path, exclude=None): \n",
    "    self._load(ckpt_path, exclude) \n",
    "            \n",
    "def _load(self, ckpt_path, exclude): \n",
    "    init_fn = slim.assign_from_checkpoint_fn(ckpt_path, \n",
    "                                             slim.get_variables_to_restore(exclude=exclude), \n",
    "                                             ignore_missing_vars=True) \n",
    "    init_fn(self.config[\"sess\"])\u2028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 224, 224, 3], name=\"X\") \n",
    "y = tf.placeholder(tf.int32, [None, 8], name=\"y\") \n",
    "is_training = tf.placeholder(tf.bool, name=\"is_training\") \n",
    "with slim.arg_scope(vgg.vgg_arg_scope()): \n",
    "    net, end_pts = vgg.vgg_16(X, is_training=is_training,\n",
    "                              num_classes=1000) \n",
    "    with tf.variable_scope(\"losses\"): \n",
    "        cls_loss = slim.losses.softmax_cross_entropy(net, y) \n",
    "        reg_loss = tf.add_n(slim.losses.get_regularization_losses()) \n",
    "        loss_op = type_loss + reg_loss \n",
    "        \n",
    "        with tf.variable_scope(\"opt\"): \n",
    "            opt = tf.train.AdamOptimizer(0.001).minimize(loss_op) \n",
    "            self.load_from_path(ckpt_path=VGG_PATH, exclude=[\"vgg_16/fc8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorzBoard & slim example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "slim = tf.contrib.slim \n",
    "# Import MINST data \n",
    "from tensorflow.examples.tutorials.mnist import input_data \n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True) \n",
    "\n",
    "max_steps = 10000 \n",
    "batch_size = 128 \n",
    "lr = 0.001 \n",
    "keep_prob = 0.5 \n",
    "weight_decay = 0.0004 \n",
    "logs_path = \"/tmp/tensorflow_logs/example\" \n",
    "\n",
    "def my_arg_scope(is_training, weight_decay): \n",
    "    with slim.arg_scope([slim.conv2d], \n",
    "                        activation_fn=tf.nn.relu, \n",
    "                        weights_regularizer=slim.l2_regularizer(weight_decay), \n",
    "                        weights_initializer=slim.variance_scaling_initializer(), \n",
    "                        biases_initializer=tf.zeros_initializer, stride=1, padding=\"SAME\"): \n",
    "        with slim.arg_scope([slim.dropout], \n",
    "                            is_training=is_training) as arg_sc: \n",
    "            return arg_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_net(x, keep_prob, outputs_collections=\"my_net\"): \n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1]) \n",
    "    \n",
    "    with slim.arg_scope([slim.conv2d, slim.max_pool2d], \n",
    "                        outputs_collections=outputs_collections): \n",
    "        net = slim.conv2d(x, 64, [3, 3], scope=\"conv1\") \n",
    "        net = slim.max_pool2d(net, [2, 2], scope=\"pool1\") \n",
    "        net = slim.conv2d(net, 128, [3, 3], scope=\"conv2\") \n",
    "        net = slim.max_pool2d(net, [2, 2], scope=\"pool2\") \n",
    "        net = slim.conv2d(net, 256, [3, 3], scope=\"conv3\") \n",
    "        # global average pooling \n",
    "        net = tf.reduce_mean(net, [1, 2], name=\"pool3\", keep_dims=True) \n",
    "        net = slim.dropout(net, keep_prob, scope=\"dropout3\") \n",
    "        net = slim.conv2d(net, 1024, [1, 1], scope=\"fc4\") \n",
    "        net = slim.dropout(net, keep_prob, scope=\"dropout4\") \n",
    "        net = slim.conv2d(net, 10, [1, 1], \n",
    "                          activation_fn=None, scope=\"fc5\") \n",
    "        \n",
    "        end_points = \\\n",
    "        slim.utils.convert_collection_to_dict(outputs_collections) \n",
    "        \n",
    "        return tf.reshape(net, [-1, 10]), end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard & slim example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "y = tf.placeholder(tf.float32, [None, 10]) \n",
    "is_training = tf.placeholder(tf.bool) \n",
    "\n",
    "with slim.arg_scope(my_arg_scope(is_training, weight_decay)): \n",
    "    net, end_pts = my_net(x, keep_prob) \n",
    "    pred = slim.softmax(net, scope=\"prediction\") \n",
    "    \n",
    "with tf.variable_scope(\"losses\"): \n",
    "    cls_loss = slim.losses.softmax_cross_entropy(net, y) \n",
    "    reg_loss = tf.add_n(slim.losses.get_regularization_losses()) \n",
    "    loss_op = cls_loss + reg_loss \n",
    "        \n",
    "with tf.variable_scope(\"Adam\"): \n",
    "    opt = tf.train.AdamOptimizer(lr) \n",
    "    # Op to calculate every variable gradient \n",
    "    grads = tf.gradients(loss_op, tf.trainable_variables()) \n",
    "    grads = list(zip(grads, tf.trainable_variables())) \n",
    "    # Op to update all variables according to their gradient \n",
    "    apply_grads = opt.apply_gradients(grads_and_vars=grads) \n",
    "            \n",
    "with tf.variable_scope(\"accuracy\"): \n",
    "    correct_op = tf.equal(tf.argmax(net, 1), tf.argmax(y, 1)) \n",
    "    acc_op = tf.reduce_mean(tf.cast(correct_op, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a summary to monitor loss and accuracy \n",
    "\n",
    "summ_loss = tf.summary.scalar(\"loss\", loss_op) \n",
    "summ_acc = tf.summary.scalar(\"accuracy_test\", acc_op) \n",
    "\n",
    "# Create summaries to visualize weights and grads \n",
    "for var in tf.trainable_variables(): \n",
    "    tf.summary.histogram(var.name, var, collections=[\"my_summ\"]) \n",
    "for grad, var in grads: \n",
    "    tf.summary.histogram(var.name + \"/gradient\", grad, \n",
    "                         collections=[\"my_summ\"]) \n",
    "    \n",
    "    summ_wg = tf.summary.merge_all(key=\"my_summ\") \n",
    "    \n",
    "    sess = tf.Session() \n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    summary_writer = tf.summary.FileWriter(logs_path, \n",
    "                                           graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for step in range(max_steps): \n",
    "    batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
    "    _, loss, plot_loss, plot_wg = sess.run([apply_grads, loss_op, \n",
    "                                            summ_loss, summ_wg], \n",
    "    feed_dict={x: batch_X, y: batch_y, is_training: True}) \n",
    "    \n",
    "    summary_writer.add_summary(plot_loss, step) \n",
    "    summary_writer.add_summary(plot_wg, step) \n",
    "    \n",
    "    if (step+1) % 100 == 0: \n",
    "        plot_acc = sess.run(summ_acc, feed_dict={x: mnist.test.images, \n",
    "                                                 y: mnist.test.labels, \n",
    "                                                 is_training: False}) \n",
    "        \n",
    "        summary_writer.add_summary(plot_acc, step) \n",
    "        \n",
    "        print(\"Optimization Finished!\") \n",
    "        \n",
    "        test_acc = sess.run(acc_op, feed_dict={x: mnist.test.images, \n",
    "                                               y: mnist.test.labels, \n",
    "                                               is_training: False}) \n",
    "        \n",
    "        print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}